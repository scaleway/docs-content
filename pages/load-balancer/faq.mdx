---
title: Load Balancer FAQ
description: Discover Scaleway Load Balancer and find the answers to all your questions about flexible IP addresses, IPv6, multi-cloud offers and more.
dates:
  validation: 2025-12-19
productIcon: LbProductIcon
---

## Overview

### What is a Load Balancer?

Load Balancers are highly available and fully managed Instances, configured to distribute workload across a set of backend servers. They allow you to scale applications hosted at the backend, while ensuring their continuous availability through the Load Balancer. Load Balancers are therefore commonly used to improve the performance and reliability of websites, applications, databases, and other services.

Scaleway Load Balancer monitors the availability of your backend servers via health checks. If it detects that a server is down, it rebalances the load between the rest of the servers, making your applications highly available for users.

A Load Balancer can be used as frontend for any type of backend server, even if it is not a Scaleway resource, thanks to the [multi-cloud feature](/load-balancer/faq/#what-is-the-difference-between-multi-cloud-and-non-multi-cloud-offers).

### What is a flexible IP address?

By default, each [public](/load-balancer/concepts/#accessibility) Load Balancer is created automatically with a flexible IPv4 address. This is a public IP that can be held in your account even after you delete your Load Balancer. You can optionally also add an IPv6 address.

**This IP address is fixed and does not risk changing once attached to your Load Balancer**.

Your frontend listens to your Load Balancer's public flexible IP address. In case of a failure of the Load Balancer, a replica Load Balancer is immediately spawned and deployed, and the IP address is automatically rerouted to this replica. This is done automatically by the Load Balancer control subsystems.

When you delete a Load Balancer, you can choose to keep its flexible IP(s) in your account, to reuse later with a new Load Balancer. These flexible IPs are not compatible with other Scaleway products (e.g. Instances, Elastic Metal servers, Public Gateways): each resource has its own set of flexible IPs.

### What is the difference between multi-cloud and non multi-cloud offers?

Multi-cloud means that you can add backend servers that are neither Instances, nor Elastic Metal servers, nor Dedibox dedicated servers. These can be services from other cloud platforms such as Amazon Web Services, Digital Ocean, Google Cloud, Microsoft Azure or OVH, but also on-premises servers hosted in a third-party data center.

Unlike the multi-cloud offers, non-multi-cloud offers allow you to add only backend servers that are part of the Scaleway ecosystem, which include Instances, Elastic Metal servers, and Dedibox dedicated servers.

To take advantage of multi-cloud, you must choose a compatible Load Balancer offer type when creating your Load Balancer, or [resize](/load-balancer/how-to/resize-lb/) to such an offer afterwards.

### What is a route?

Once you have created one or more Load Balancers, you can create routes. Routes indicate how to direct incoming connections to certain backends based on various parameters such as IP addresses, path, host, etc. You can choose the frontend to which the rule should apply, and the backend it should direct to. Routes can be based on **Server Name Indication** (SNI) for TCP Load Balancers, or the **HTTP Host header** or **URL path** for HTTP Load Balancers. Check out our [dedicated documentation](/load-balancer/how-to/create-manage-routes/) for more information.

## Offering and availability

### Is there a failover system for Load Balancers?

Yes. If your Load Balancer fails, a deployment script automatically executes, spawning and deploying a replica Load Balancer Instance. Your Load Balancer's flexible IP address is automatically rerouted to this replica Instance.
If you want to know more about the failover system, read [our article about strengthening our Load Balancer failover mechanism](https://www.scaleway.com/en/blog/strengthening-our-load-balancer-failover-mechanism/).

## Specifications

### Do backend servers require a public IP address?

No, this is not necessary. Your Load Balancer can reach your backend servers via their private IP addresses on a Private Network, as long as the Load Balancer and servers are all in the same region/VPC.

## Quotas and limitations

### Can I have more than one flexible IP address for a Load Balancer?

Each Load Balancer can have one public IPv4 address and one public IPv6 address. Currently, it is not possible to assign more than one of each type of IP to a given Load Balancer.

### Can I add multiple backends to a frontend?

Yes, this is possible using routes. When you create a frontend, you must select a "default" backend, to which it forwards traffic when the request doesn't match any configured route. But via the **routes** tab for your frontend in the Scaleway console, you can create routes to different backends from the same frontend. Routes are currently supported based on the value of the `Host` header of incoming HTTP requests for HTTP backends, URL paths, or on SNI for TCP backends.

## Compatibility and integration

### What are the communication protocols currently supported?

All protocols based on `TCP` are supported. This includes `database`, `HTTP`, `LDAP`, `IMAP`, and so on. You can also specify `HTTP` to benefit from support and features that are exclusive to this protocol.

Scaleway Load Balancer does not currently support `UDP`.

### Can I use Load Balancers with other products?

Yes: Check out our documentation on:
- [Using a Load Balancer to expose a Kubernetes Kapsule](/kubernetes/reference-content/kubernetes-load-balancer/)
- [Setting up caching for your Load Balancer via Edge Services](/edge-services/quickstart/)

### Do Load Balancers support external IPv6 connections?

Yes, Load Balancer supports both IPv4 and IPv6 addresses at the frontend. IPv6 can also be used to communicate between the Load Balancer and your backend servers.

## Access and security

### What is a health check?

A health check is one of the core concepts for a well-functioning Load Balancer. It is a predefined request which periodically checks whether the server is in a healthy state or an unhealthy state. Only servers that respond correctly to the health check receive client requests. When the Load Balancer determines that an Instance is unhealthy, it stops routing requests to that Instance. Currently, our Load Balancer supports `TCP` and `TCP-based` health checks such as `HTTP(S)`, `LDAP`, `REDIS`, etc. [Find out more about health checks](/load-balancer/reference-content/configuring-health-checks/).

### Can I set up a caching service for my load balanced application?

Yes, this is possible with Scaleway's [Edge Services](/edge-services/) product, currently in Public Beta. By creating an Edge Services pipeline for your Load Balancer, you can access Edge Services caching service reduce load on your origin.

### How can I add extra security such as a firewall or anti-DDOS to my Load Balancer?

You can add a **W**eb **A**pplication **F**irewall to your Load Balancer via [Edge Services](/edge-services/reference-content/understanding-waf/).

### Is there a Service Level Agreement (SLA) for Load Balancers?

Yes, see [the dedicated documentation page](https://www.scaleway.com/en/load-balancer/sla/).

### Is it possible to add security to restrict access to a URL or port on the Load Balancer?

Yes, you can restrict the use of a `TCP` port or `HTTP` URL using ACLs. Find more information in our [ACL documentation](/load-balancer/how-to/create-manage-acls/).

## Usage and management

### How can I move my Instance's flexible IP address to my Load Balancer?

This is not possible: flexible IPs are scoped to the resource-type that they were created for. You can move a flexible IP between different Instances, but not move it to a Load Balancer.

Watch this space for resource-agnostic flexible IPs in the future.