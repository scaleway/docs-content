---
title: Supported models
description: This page lists which open-source chat or embedding models Scaleway is currently hosting
tags: generative-apis ai-data supported-models
dates:
  validation: 2025-09-12
  posted: 2024-09-02
---

Our API supports the most popular models for [Chat](/generative-apis/how-to/query-language-models), [Vision](/generative-apis/how-to/query-vision-models/), [Audio](/generative-apis/how-to/query-audio-models/) and [Embeddings](/generative-apis/how-to/query-embedding-models/).

## Multimodal models

### Chat and Vision models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License \* | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Google (Preview)   | `gemma-3-27b-it`  | 40k  | 8k | [Gemma](https://ai.google.dev/gemma/terms) | [HF](https://huggingface.co/google/gemma-3-27b-it) |
| Mistral | `mistral-small-3.2-24b-instruct-2506`  | 128k  | 32k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506) |
| H | `holo2-30b-a3b`  | 22k  | 32k | [CC-BY-NC-4.0](https://spdx.org/licenses/CC-BY-NC-4.0) | [HF](https://huggingface.co/Hcompany/Holo2-30B-A3B) |

\*Licences which are not open-weight and may restrict commercial usage (such as `CC-BY-NC-4.0`), do not apply to usage through Scaleway Products due to existing partnerships between Scaleway and the corresponding providers. Original licences are provided for transparency only.

### Chat and Audio models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Mistral | `voxtral-small-24b-2507`  | 32k  | 16k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Voxtral-Small-24B-2507) |

### Audio transcription models

| Provider | Model string | Maximum audio duration (Minutes) | Chunk size (Seconds) | Maximum file size (MB) | License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Mistral | `voxtral-small-24b-2507`  | 30 | 30 | 25 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Voxtral-Small-24B-2507) |
| OpenAI | `whisper-large-v3`  | - | 30 | 25 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/openai/whisper-large-v3) |

## Chat models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| OpenAI        | `gpt-oss-120b`  | 128k  | 32k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/openai/gpt-oss-120b) |
| Meta        | `llama-3.3-70b-instruct`  | 100k  | 16k | [Llama 3.3 Community](https://www.llama.com/llama3_3/license/) | [HF](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) |
| Meta        | `llama-3.1-8b-instruct`  | 128k  | 16k | [Llama 3.1 Community](https://llama.meta.com/llama3_1/license/) | [HF](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) |
| Mistral      | `mistral-nemo-instruct-2407`   | 128k | 8k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407) |
| Mistral      | `devstral-2-123b-instruct-2512`     | 200k | 16k | [Modified MIT](https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512/blob/main/LICENSE) | [HF](https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512) |
| Qwen      | `qwen3-235b-a22b-instruct-2507`     | 250k | 16k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507) |
| Qwen      | `qwen3-coder-30b-a3b-instruct`     | 128k | 32k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct) |
| DeepSeek  | `deepseek-r1-distill-llama-70b`     | 16k | 4k | [MIT](https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/mit.md) | [HF](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B) |

<Message type="tip">
  If you are unsure which chat model to use, we currently recommend Mistral Small 3.2 24B Instruct (`mistral-small-3.2-24b-instruct-2506`) to get started.
</Message>

## Vision models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Mistral      | `pixtral-12b-2409`    | 128k | 4k | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Pixtral-12B-2409) |

<Message type="note">
  Image sizes are limited to 32 million pixels (e.g., a resolution of about 8096 x 4048). Images with a resolution higher than 1024 x 1024 are supported, but automatically downscaled to fit these limitations (image ratio and proportions will be preserved).
</Message>

## Embedding models

Our [Embeddings API](/generative-apis/how-to/query-embedding-models) provides built-in support for the following models, hosted in Scaleway data centers, available via serverless endpoints.

| Provider | Model string | Embedding dimension (Maximum) | Embedding dimensions (Minimum) | Context window |  License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Qwen        | `qwen3-embedding-8b`  | 4096  | 32 | 32 000 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/Qwen/Qwen3-Embedding-8B) |
| BAAI        | `bge-multilingual-gemma2`  | 3584  | 3584 | 8192 | [Gemma](https://ai.google.dev/gemma/terms) | [HF](https://huggingface.co/BAAI/bge-multilingual-gemma2) |

## Request a model

**Do not see a model you want to use?** [Tell us or vote for what you would like to add here.](https://feature-request.scaleway.com/?tags=ai-services)

## Deprecated models

These models can still be accessed in Generative APIs, but their End of Life (EOL) is planned according to our [model lifecycle policy](/generative-apis/reference-content/model-lifecycle/).
Deprecated models should not be queried anymore. We recommend to use newer models available in Generative APIs or to deploy these models in dedicated [Managed Inference](https://console.scaleway.com/inference/deployments) deployments.

| Provider | Model string | Deprecation date | End of Life (EOL) date | After End of Life date, requests routed to model
|-----------------|-----------------|-----------------|-----------------|-----------------|
| Deepseek | `deepseek-r1-distill-llama-70b`  |  16th January, 2026 | 16th April, 2026 | `llama-3.3-70b-instruct` |
| Mistral | `mistral-nemo-instruct-2407`  | 16th January, 2026 | 16th April, 2026 | `mistral-small-3.2-24b-instruct-2506` |
| Meta     | `llama-3.1-8b-instruct`     | 16th January, 2026 | 16th April, 2026 | `mistral-small-3.2-24b-instruct-2506` |

## End of Life (EOL) models

These models are not accessible anymore from Generative APIs. They can still however be deployed on dedicated [Managed Inference](https://console.scaleway.com/inference/deployments) deployments.

| Provider | Model string | EOL date | Requests routed to model
|-----------------|-----------------|-----------------|-----------------|
| Mistral | `mistral-small-3.1-24b-instruct-2503`  | 14th November, 2025 | `mistral-small-3.2-24b-instruct-2506` |
| Mistral | `devstral-small-2505`  | 14th November, 2025 | `qwen3-coder-30b-a3b-instruct` |
| Qwen      | `qwen2.5-coder-32b-instruct`     | 14th November, 2025 | `qwen3-coder-30b-a3b-instruct` |
| Meta    | `llama-3.1-70b-instruct` | 25th May, 2025 | `llama-3.3-70b-instruct` |
| SBERT      | `sentence-t5-xxl`  | 26 February, 2025 | None |
