---
meta:
  title: LLM Inference Documentation
  description: Dive into Scaleway LLM Inference with our quickstart guides, how-tos, tutorials and more.
content:
  h1: LLM Inference Documentation
  paragraph: Dive into Scaleway LLM Inference with our quickstart guides, how-tos, tutorials and more.
---

<ProductHeader
   productName="LLM Inference"
   productLogo="inference"
   description="Dive into seamless language processing with our easy-to-use LLM endpoints. Perfect for everything from data analysis to creative tasks, all with clear pricing."
   url="/ai-data/llm-inference/quickstart"
   label="LLM Inference Quickstart"
/>

## Getting Started

<Grid>
    <SummaryCard
        title="Quickstart"
        icon="rocket"
        description="Learn how to create, connect to, and delete an LLM endpoint in a few steps."
        label="View Quickstart"
        url="/ai-data/llm-inference/quickstart/"
    />
    <SummaryCard
        title="Concepts"
        icon="information-circle-outline"
        description="Core concepts that give you a better understanding of Scaleway LLM Inference."
        label="View Concepts"
        url="/ai-data/llm-inference/concepts/"
    />
    <SummaryCard
        title="How-tos"
        icon="help-circle-outline"
        description="Check our guides about creating and managing LLM endpoints."
        label="View How-tos"
        url="/ai-data/llm-inference/how-to/"
    />
    <SummaryCard
        title="Additional content"
        icon="book-open-outline"
        description="Guides to help you choose an LLM endpoint, understand pricing and advanced configuration."
        label="View additional content"
        url="/ai-data/llm-inference/reference-content/"
    />
</Grid>

<ClickableBanner
    productLogo="cli"
    title="LLM Inference API"
    description="Learn how to create and manage your Scaleway LLM endpoints through the API."
    url="https://www.scaleway.com/en/developers/api/llm-inference/"
    label="Go to LLM Inference API"
/>

## Changelog

<ChangelogList
    productName="llm-inference"
    numberOfChanges={3}
/>
