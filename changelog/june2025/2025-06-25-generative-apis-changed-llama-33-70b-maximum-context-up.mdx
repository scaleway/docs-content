---
title: Llama 3.3 70B maximum context update
status: changed
date: 2025-06-25
category: ai-data
product: generative-apis
---

Llama 3.3 70B maximum context is [now reduced to 100k tokens](https://www.scaleway.com/en/docs/generative-apis/reference-content/supported-models/) (from 130k tokens previously). 
This update will improve average throughput and time to first token. 
[Managed Inference](https://www.scaleway.com/en/docs/managed-inference/reference-content/model-catalog/) can still be used to support 130k tokens context length.

