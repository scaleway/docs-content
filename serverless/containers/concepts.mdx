---
meta:
  title: Containers - Concepts
  description: Key concepts of Scaleway Serverless Containers.
content:
  h1: Containers - Concepts
  paragraph: Key concepts of Scaleway Serverless Containers.
tags: containers cold-start concurrency container-registry environment-variables jwt vcpu serverless scale autoscaling
dates:
  validation: 2024-11-14
categories:
  - serverless
---

## Cold Start

Cold start is the time a Container takes to handle a request when it is called for the first time.

Startup process steps are:
* Downloading the container image to our infrastructure
* Starting the container. Optimize your container startup speed to minimize this step (e.g., avoid waiting for slow connections or downloading large objects at startup)
* Waiting for the container to listen on the configured port.

[How to reduce cold starts](/faq/serverless-containers/#how-can-i-reduce-the-cold-starts-of-serverless-containers)

## Concurrency

Concurrency defines the number of simultaneous requests a single instance of your container can handle at the same time. Once the number of incoming requests exceeds this value, your container scales according to your parameters.

Refer to the [dedicated documentation](/serverless/containers/reference-content/containers-concurrency/) for more information on container concurrency.

## Container

A container is a package of software that includes all dependencies: code, runtime, configuration, and system libraries so that it can run on any host system. Scaleway provides custom Docker images that are entirely handled for you in the cloud.

## Container Registry

Container Registry is the place where your images are stored before being deployed, we recommend using Scaleway Container Registry for a better integration. [Migration guide](/serverless/containers/api-cli/migrate-external-image-to-scaleway-registry/).

## CRON trigger

A CRON trigger is a mechanism used to automatically invoke a Serverless Function at a specific time on a recurring schedule.

It works similarly to a traditional Linux [cron job](https://en.wikipedia.org/wiki/Cron), using the `* * * * *` format, and uses the **UTC** time zone. Refer to our [cron schedules reference](/serverless/containers/reference-content/cron-schedules/) for more information.

## Custom domain

By default a generated endpoint is assigned to your Serverless ressource and custom domains allows you to use your own domain read [custom domain documentation](/serverless/containers/how-to/add-a-custom-domain-to-a-container).

## Deployment

Some parameters requires a new deployment of the Container to take affect and it creates a Deployment. Rollout of a deployment will not cause downtime and the traffic switches smoothly to the newest revision.

## Endpoint

An endpoint is the URL generated to access your ressource, it can be customised with Custom Domains.

## Environment variables

Environment variables are key/value pairs injected in your container. It's useful to share informations such as configuration with your container. Some names are reserved [details about reserved names](/serverless/containers/reference-content/containers-limitations/#configuration-restrictions).

## Ephemeral storage

In addition to vCPU and RAM, Serverless Containers also provide a storage volume for the duration of the task. This storage space allows to hold the data retrieved by the job, and disappears once the execution is complete.

The maximum size of the ephemeral storage is tied to the allocated memory.

## GB-s

Unit used to measure the resource consumption of a container. It reflects the amount of memory consumed over time.

## gRPC

gRPC is supported on Serverless Containers, it requires to enable http2 (`h2c`) protocol.

## Healthcheck

To determine the `Status` of a Serverless Containers, default healthecks automatically checks if basic requirements are met to define the status as `ready`.

It's possible to define custom healthecks rules with a specific endpoint via the API: [read API doc](https://www.scaleway.com/en/developers/api/serverless-containers/#path-containers-create-a-new-container).

## Instance

Depending incoming requests, min scale and max scale, a Serverless Container instance processes incoming requests.

## JWT Token

JWT (JSON Web Token) is an access token you can create from the console or API to enable an application to access your Private Container. [More details about how to secure a Container](/serverless/containers/how-to/secure-a-container/#restrict-access-to-your-containers)

## Load balancing

Incoming request traffic is managed by the Serverless infrastructure. In some cases such as rapid traffic changes or load testing, depending max scale parameter the ressources are automatically allocated to manage the traffic.

## Max scale

It's the maximum number of instances of your Container. Define this parameter according to the traffic spikes of your Container. In some cases you may want to limit the max scale for cost control reasons.

## Min scale

Customizing min scale for Serverless can be useful to keep an instance warm and limit cold starts. It also have an impact on costs of your Serverless Container.

## mvCPU

A [vCPU](#vcpu) (Virtual Central Processing Unit) is equivalent to 1000 mvCPU.

## Namespace

A namespace is a project that allows you to [group your containers](/serverless/containers/how-to/create-manage-delete-containers-namespace/).

Containers in the same namespace can share environment variables, secrets and access tokens, defined at the namespace level.

## NATS trigger

A NATS trigger is a mechanism that connects a container to a [NATS](/serverless/messaging/concepts/#nats) subject and invokes the container automatically whenever a message is published to the subject.

For each message that is sent to a NATS subject, the NATS trigger reads the message and invokes the associated container with the message as the input parameter.
The container can then process the message and perform any required actions, such as updating a database or sending a notification.

## Port

The port parameter specifies the network port that your container listens on for incoming requests. If your application or container is set up to listen on a different port, you must specify it using the port parameter when deploying your container to Serverless Containers. It must reflect the port configuration within your container for your service to function correctly.

The value defined in the port parameter will then be passed to your container during the deployment inside the `PORT` environment variable.

## Privacy policy

A container's privacy policy defines whether a container may be invoked anonymously (**public**) or only via an authentication mechanism provided by the [Scaleway API](https://www.scaleway.com/en/developers/api/serverless-containers/#authentication) (**private**).

## Registry endpoint

Registry endpoint parameter is the ressource link to the container image used in the Serverless Container.

## Sandbox

A sandbox is an isolation area for your container. Serverless Containers offer two sandboxing environments:
- **v2** - Recommended for faster cold starts.
- **v1** - Legacy sandboxing with slower cold starts, but fully supports Linux system call interface.

## Scale to zero

One of the advantages of Serverless Containers is that when your container is not triggered, it does not consume any resources, which enables great savings.

## Scaling

Serverless Containers make scaling your application transparent, up to 50 instances of your container can be run at the same time.

## Secrets

Secrets are an extra-secure type of environment variable. They are environment variables that are injected into your container and stored securely, but not displayed in the console after initial validation.

## Serverless

Serverless allows you to deploy your Functions (FaaS) and Containerized Applications (CaaS) in a managed infrastructure. Scaleway ensures the deployment, availability, and scalability of all your projects.

## Serverless Framework

Serverless.com (Serverless Framework) is a tool that allows you to deploy serverless applications without having to manage Serverless Container's API call. Write and deploy a YAML configuration file, everything else is handled automatically, even the image building.

## Serverless Job

Serverless Jobs are close to Serverless Containers but it's more adapted to run long workloads, see [comparaison between Serverless products](/serverless/containers/reference-content/difference-jobs-functions-containers.mdx).

## SQS trigger

An SQS (Simple Queue Service) trigger is a mechanism that connects a container to an [SQS](/serverless/messaging/concepts/#sqs) queue and invokes the container automatically whenever a message is added to the queue.

For each message that is sent to an SQS queue, the SQS trigger reads the message and invokes the associated container with the message as the input parameter.
The container can then process the message and perform any required actions, such as updating a database or sending a notification.

## Stateless application

A stateless application is a computer program that does not save client data between sessions. Data generated in one session is not saved for use in the next session with that client.

To store data persistently, use products like Databases or Object Storage.

## Status

A Serverless Container can be:
* **Ready**: your Serverless Container is operational to serve requests.
* **Pending**: your ressource is under deployment.
* **Error**: something failed in the deploymen process, [open troubleshooting documentation](/serverless/containers/troubleshooting/cannot-deploy-image.mdx).

## Terraform

Terraform is an infrastructure as code tool, [read terraform documentation of Serverless Containers](https://registry.terraform.io/providers/scaleway/scaleway/latest/docs/resources/container).

## Timeout

The timeout is the maximum length of time your container can spend processing a request before being stopped. This value must be in the range 10s to 900s.

## vCPU

vCPU is the abbreviation for **v**irtual **C**entralized **P**rocessing **U**nit. A vCPU represents a portion or share of the underlying physical CPU assigned to a particular container.
The performance of a vCPU is determined by the percentage of time spent on the physical processor's core. It is possible to allocate different resource allowances on specific vCPUs for specific containers or virtual machines.

## vCPU-s

Unit used to measure the resource consumption of a container. It reflects the amount of vCPU used over time.

## Protocol

Serverless Containers supports **http1** (default) and **http2** (`h2c`). Use HTTP/2 if your container application is configured to listen for HTTP/2 requests, such as a **gRPC** service or a web server that uses HTTP/2 features like multiplexing, otherwise HTTP/1 is recommended.
