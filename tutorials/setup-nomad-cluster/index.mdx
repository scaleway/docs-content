---
meta:
  title: Setup a Nomad cluster on Scaleway
  description: This tutorial will guide you you through deploying a Nomad cluster with access control lists (ACLs) on Scaleway.
content:
  h1: Setup a Nomad cluster on Scaleway
  paragraph: This tutorial will guide you through deploying a Nomad cluster with access control lists (ACLs) on Scaleway.
tags: compute orchestration nomad cluster consul packer terraform
author: 
    fullname: Nathanael Demacon
    url: ''
categories:
  - compute
dates:
  validation: 2023-03-20
  posted: 2023-03-20
---

<Macro id="iam-requirements" />
 
<Message type="requirement">
  - You have an account and are logged into the [Scaleway console](https://console.scaleway.com)
  - You have [configured an API key](/identity-and-access-management/iam/how-to/create-api-keys/)
  - Packer 1.7.7 or later [installed locally](https://developer.hashicorp.com/packer/tutorials/docker-get-started/get-started-install-cli)
  - Terraform 1.2.0 or later [installed locally](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli)
  - Nomad 1.3.3 or later [installed locally](https://developer.hashicorp.com/nomad/tutorials/get-started/get-started-install)
</Message>

## Clone the repository

We have created a GitHub repository that should contain all the code you need to deploy a Nomad cluster on Scaleway. Clone the repository to your local machine using the following command:

```shell
git clone https://github.com/scaleway/learn-nomad-cluster-setup.git
```

Go to the `learn-nomad-cluster-setup/scaleway` directory to continue with the tutorial:

```shell
cd learn-nomad-cluster-setup/scaleway
```

### Files and directories

In the `scaleway` directory, you will find the following files:

- `image.pkr.hcl` - The Packer configuration file used to build the Nomad instance image.
- `main.tf` - The Terraform configuration file used to deploy the Nomad cluster.
- `variables.tf` - The Terraform variables file used to configure the Nomad cluster.
- `post-setup.sh` - The script used to bootstrap the Nomad cluster.
- `variables.hcl.example` - An example variables file used to configure the Nomad cluster.

We will be using the `variables.hcl.example` file to configure the Nomad cluster. Copy the example file to a new file called `variables.hcl` using the following command:

```shell
cp variables.hcl.example variables.hcl
```

---

## Configure the Nomad token

Open the `variables.hcl` file in your favorite text editor and update the following variables:

- `nomad_consul_token_id` - The Consul token ID used to bootstrap the Nomad cluster.
- `nomad_consul_token_secret` - The Consul token secret used to bootstrap the Nomad cluster.

These variables needs to be uuids. You can generate a uuid using uuidgen:

```shell
uuidgen | tr "[:upper:]" "[:lower:]"
```

Or using Terraform console's `uuid()` function:

```shell
terraform console
> uuid()
"4fda5224-6d40-20dd-5dd4-4ce95c1026fb"
> uuid()
"46c99dc9-3536-9a30-8175-92f0b220f688"
```

We will configure the `instance_image` variable in the next step. You can uncomment and configure the rest of the variables as you wish or leave them as they are.

---

## Build the Nomad instance image

Build the Nomad instance image using Packer using the following command:

```shell
packer build -var-file=variables.hcl image.pkr.hcl
```

At the end of the build process, you should see the following output:

```shell
Build 'scaleway.hashistack' finished after 2 minutes 54 seconds.

==> Wait completed after 2 minutes 54 seconds

==> Builds finished. The artifacts of successful builds are:
--> scaleway.hashistack: An image was created: 'hashistack-[random-number]' ...
```

Copy the image name from the output and paste it in the `variables.hcl` file to configure the `instance_image` variable.


**Example variables.hcl:**

At this step your `variables.hcl` file should look like the following **(don't take the same Consul token ID and secret)**:

```hcl
# Packer variables (all are required)
zone = "fr-par-1"

# Terraform variables (all are required)
nomad_consul_token_id     = "4fda5224-6d40-20dd-5dd4-4ce95c1026fb"
nomad_consul_token_secret = "6ae9f6f7-b6f1-4d3a-ea82-bcbea392daa0"
instance_image            = "hashistack-20230310141424"

# The project ID will default to the value of the
# SCW_DEFAULT_PROJECT_ID environment variable or the
# default project ID configured with the Scaleway CLI
# project_id                    = "123e4567-e89b-12d3-a456-426614174000"

# The retry join allows Consul to automatically
# discover other nodes in the cluster. An IAM key will
# be created in Terraform and appended to the retry_join
# variable
# retry_join                    = "provider=scaleway tag_name=consul-auto-join"

# These variables will default to the values shown
# and do not need to be updated unless you want to
# change them
# allowlist_ip                  = "0.0.0.0/0"
# name                          = "nomad"
# server_instance_type          = "PLAY2-NANO"
# server_count                  = "3"
# server_root_block_device_size = 20
# client_instance_type          = "PLAY2-NANO"
# client_count                  = "3"
```

---

## Deploy the Nomad cluster

Now that we have built the Nomad instance image and configuring our variables, we can deploy the Nomad cluster using Terraform.

Initialize Terraform using the following command:

```shell
terraform init
```

Deploy the Nomad cluster using the following command:

```shell
terraform apply -var-file=variables.hcl
```

At the end of the deployment process, you should see the following output:

```shell
Apply complete! Resources: 1 added, 7 changed, 2 destroyed.

Outputs:

IP_Addresses = <<EOT

Client public IPs: 163.172.187.210, 163.172.167.58, 163.172.177.35

Server public IPs: 163.172.146.151, 212.47.247.102, 51.15.229.185

Server public IPs: 2

The Consul UI can be accessed at http://163.172.146.151:8500/ui
with the bootstrap token: 6ae9f6f7-b6f1-4d3a-ea82-bcbea392daa0

EOT
consul_bootstrap_token_secret = "6ae9f6f7-b6f1-4d3a-ea82-bcbea392daa0"
lb_address_consul_nomad = "http://163.172.146.151"
```

---

## Use the Nomad CLI

To setup your local environment to use the Nomad CLI, run the `post-setup.sh` script:

```shell
./post-setup.sh
```

The script will give you the commands to setup `NOMAD_ADDR` and `NOMAD_TOKEN` environment variables:

```shell
The Nomad user token has been saved locally to nomad.token and deleted from the Consul KV store.

Set the following environment variables to access your Nomad cluster with the user token created during setup:

export NOMAD_ADDR=$(terraform output -raw lb_address_consul_nomad):4646
export NOMAD_TOKEN=$(cat nomad.token)


The Nomad UI can be accessed at http://163.172.146.151:4646/ui
with the bootstrap token: 192049fd-52f7-4fa7-7797-b28b78bfcf84
```

Execute the commands to setup the environment variables:

```shell
export NOMAD_ADDR=$(terraform output -raw lb_address_consul_nomad):4646
export NOMAD_TOKEN=$(cat nomad.token)
```

You can now use the Nomad CLI to interact with the Nomad cluster:

```shell
nomad node status
```
