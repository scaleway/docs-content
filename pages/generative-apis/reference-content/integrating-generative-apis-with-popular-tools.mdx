---
title: Integrating Scaleway Generative APIs with popular AI tools
description: Learn how to integrate Scaleway's Generative APIs with popular AI tools to unlock the full potential of your applications.
tags: generative-apis ai language-models
dates:
  validation: 2025-08-26
  posted: 2025-02-18
---

Scaleway's Generative APIs are designed to provide easy access to the latest AI models and techniques. Our APIs are built on top of a robust infrastructure that ensures scalability, reliability, and security. With our APIs, you can integrate AI capabilities into your applications, such as text generation, image classification, and more.

## Comparison of AI tools and libraries

The following table compares AI tools and libraries supported by Scaleway's Generative APIs:

| Tool/Library | Description | Use cases | Integration effort |
| --- | --- | --- | --- |
| [OpenAI client](#openai-client-libraries) | Popular AI library for natural language processing | Text generation, language translation, text summarization | Low |
| [LangChain](#langchain-rag--llm-applications) | Library for building AI applications leveraging RAG | Inference, embeddings, document indexing and retrieval | Medium |
| [LlamaIndex](#llamaindex-advanced-rag-applications) | Library for building advanced AI RAG applications | Knowledge graph building, document retrieval, data indexing | Medium |
| [Continue Dev](#continue-dev-ai-coding-assistance) | IDE extension for AI-powered coding assistance | Code completion, code review | Low |
| [Zed AI](#zed-ai-coding-assistance) | IDE including AI-powered coding assistance | Code completion, code review | Low |
| [Cursor](#cursor-ai-coding-assistance) | IDE for AI-powered coding assistance | Code completion, code generation, code review | Low |
| [Claude Code](#claude-code-ai-coding-assistance) | Coding Agent for terminal and IDE | Code completion, code review | Low |
| [Qwen Code](#qwen-code-ai-coding-assistance) | Coding Agent for terminal and IDE | Code completion, code review | Low |
| [Bolt.diy](#boltdiy-code-generation) | Software to create applications | Code generation, code edition | Low |
| [Chatbox AI](#chatbox-ai) | Desktop client for generative APIs, available on Windows, Mac, Linux | AI copilot for documents, images, or code| Low |
| [n8n](#n8n) | Workflow automation tool | Connecting AI agents, apps, and services. | Low |
| [cURL/Python](#custom-http-integrations) | Direct HTTP API calls for custom integrations | Custom applications, data processing | High |

<Message type="note">
  The integration effort is subjective and may vary depending on the specific use case and requirements.
</Message>

## OpenAI client libraries

Scaleway Generative APIs follow OpenAI's API structure, making integration straightforward. To get started, you'll need to install the OpenAI library and set up your API key.

### Configuration

To use the OpenAI client library with Scaleway's Generative APIs, first install the required dependencies:
```bash
pip install openai
```

Then set the API key and base URL in your OpenAI-compatible client:
```python
from openai import OpenAI
client = OpenAI(
    base_url="https://api.scaleway.ai/v1",
    api_key="<API secret key>"
)
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Using OpenAI client for text generation

To use OpenAI client for text generation, you can create a `client.chat.completions` object and call the `create` method:
```python
response = client.chat.completions.create(
    model="llama-3.1-8b-instruct",
    messages=[{"role": "user", "content": "Tell me a joke about AI"}]
)
print(response.choices[0].message.content)
```

<Message type="tip">
You can also use the [Responses API](https://www.scaleway.com/en/developers/api/generative-apis/#technical-information) as an alternative to Chat Completions, but note that Scaleway's support of this API is currently at beta stage.
</Message>

## LangChain (RAG & LLM applications)

LangChain is a popular library for building AI applications. Scaleway's Generative APIs support LangChain for both inference and embeddings.

### Python

#### Function calling

1. Run the following commands to install LangChain and its dependencies:
    ```bash
    $ pip install 'langchain>=0.3.24'
    $ pip install 'langchain-core>=0.3.55'
    $ pip install 'langchain-openai>=0.3.14'
    $ pip install 'langchain-text-splitters>=0.3.8'
    ```
2. Create a file named `tools.py` and paste the code below into it to import and create the tools examples:
    ```Python
    from langchain_core.messages import HumanMessage
    from langchain.chat_models import init_chat_model
    from langchain_core.tools import tool


    @tool
    def add(a: int, b: int) -> int:
        """Adds a and b."""
        return a + b


    @tool
    def multiply(a: int, b: int) -> int:
        """Multiplies a and b."""
        return a * b


    tools = [add, multiply]
    ```
3. Configure the `init_chat_model` function to use Scaleway's Generative APIs.
    ```Python
    llm = init_chat_model("mistral-small-3.1-24b-instruct-2503", model_provider="openai", base_url="https://api.scaleway.ai/v1")
    ```
4. Use the `llm` object and the `tools` list to generate a response to your query with the following code:
    ```python
    query = "What is 3 * 12?"
    # You can also try the following query:
    # query = "What is 42 + 4?"

    messages = [HumanMessage(query)]  # We initialize the messages list with the user's query.

    ai_msg = llm_with_tools.invoke(messages)  # We generate a response to the query.
    messages.append(ai_msg)  # We append the response to the messages list.

    for tool_call in ai_msg.tool_calls:
        selected_tool = {"add": add, "multiply": multiply}[tool_call["name"].lower()]  # Depending on the tool name, we select the appropriate tool.
        tool_msg = selected_tool.invoke(tool_call)  # We invoke the selected tool with the tool call.
        messages.append(tool_msg)  # We append the tool's response to the messages list.

    print(llm_with_tools.invoke(messages).content)  # We print the content of the final response.
    ```
5. Run `tools.py`:
    ```bash
    $ python tools.py
    The result of 3 * 12 is 36.
    ```

<Message type="tip">
  Refer to our dedicated documentation for [implementing Retrieval-Augmented Generation (RAG) with LangChain and Scaleway Generative APIs](/tutorials/how-to-implement-rag-generativeapis/)
</Message>

## LlamaIndex (advanced RAG applications)

LlamaIndex is an open-source framework for building Large Language Models (LLMs) based applications, especially optimizing RAG (Retrieval Augmented Generation) pipelines.
1. Install the required dependencies to use the LlamaIndex framework with Scaleway's Generative APIs:
    ```bash
    pip install llama-index-llms-openai-like
    ```

2. Create a file `main.py` and add the following code to it to configure the `OpenAILike` client and your secret key:
    ```python
    from llama_index.llms.openai_like import OpenAILike
    from llama_index.core.llms import ChatMessage

    llm = OpenAILike(
      model="llama-3.1-8b-instruct",
      api_key="<API secret key>",
      api_base="https://api.scaleway.ai/v1",
      max_tokens=512,
      temperature=0.7,
      top_p=1,
      presence_penalty=0,
    )
    ```
    <Message type="tip">
        Make sure to replace `<API secret key>` with your actual API key.
    </Message>

3. Interact with the LLM by sending messages to the model with the following code:
    ```python
    response = llm.chat([ChatMessage("Could you tell me about Scaleway please ?")])
    print(response)
    ```

4. Finally, run `main.py`:
    ```python
    python main.py
    ```
    The LLM response should display an answer:
    ```bash
    Generally, Scaleway is a reliable and secure cloud provider that offers a range of services for businesses and developers.
    ```

### Javascript (Typescript)

To perform chat conversations with Langchain, first install `langchain` and `@langchain/openai` packages using your node package manager.

1. Use the following command to install Langchain using `npm` (`yarn` and `pnpm` are also available):
    ```bash
    npm install langchain @langchain/openai
    ```

2. Edit your `package.json` file to ensure it has the `"type": "module"` property:
    ```json
    {
      "type": "module",
      "dependencies": {
        "@langchain/openai": "^0.4.4",
        "langchain": "^0.3.19"
      }
    }
    ```

3. Create a `main.js` file and add the following content to it:
    ```js
    import { ChatOpenAI } from "@langchain/openai";

    const chat = new ChatOpenAI({
        apiKey: "<API secret key>",
        model: "llama-3.1-8b-instruct",
        configuration: {
            baseURL: "https://api.scaleway.ai/v1",
        }
      });

    const response = await chat.invoke("Tell me a joke");
    console.log(response.content);
    ```

    <Message type="tip">
      Make sure to replace `<API secret key>` with your actual API secret key.
    </Message>

4. Run `main.js`:
    ```bash
    node main.js
    ```
    The model answer should display:
    ```bash
    Why couldn't the bicycle stand up by itself? Because it was two-tired.
    ```

Note that other Langchain objects from OpenAI client library are also compatible, such as `OpenAI` and `OpenAIEmbeddings`.


## Continue Dev (AI coding assistance)

Continue Dev is a library that provides AI-powered coding assistance. Scaleway's Generative APIs support Continue Dev for code completion and more.

<Message type="tip">
  Refer to our dedicated documentation for
  - [Integrating Continue Dev with Visual Studio Code](/generative-apis/reference-content/adding-ai-to-vscode-using-continue/)
  - [Integrating Continue Dev with IntelliJ IDEA](/generative-apis/reference-content/adding-ai-to-intellij-using-continue/)
</Message>

## Zed AI (coding assistance)

Zed is an IDE (Integrated Development Environment) including AI coding assistance support. Scaleway's Generative APIs support Zed AI code completion and more.

<Message type="tip">
  Refer to our dedicated documentation for [connecting Zed to Generative APIs](/generative-apis/reference-content/adding-ai-to-zed-ide/)
</Message>

## Cursor (AI coding assistance)

Cursor is an AI-powered code editor that helps developers write and edit code more efficiently. It can read your existing codebase, help you navigate it, and generate code based on your natural language descriptions. Built on top of Visual Studio Code, it allows you to integrate language models directly into your coding workflows.

<Message type="tip">
  Refer to our dedicated documentation for [integrating Generative APIs into Cursor](/generative-apis/reference-content/integrate-with-cursor/)
</Message>

## Claude Code (AI coding assistance)

Claude Code is a coding agent for terminal and IDE. You can use Claude Code with Generative APIs by using a local proxy such as y-router.

<Message type="tip">
  Refer to our dedicated documentation for [integrating Generative APIs with Claude Code](/generative-apis/reference-content/integrate-with-claude-code/)

## Qwen Code (AI coding assistance)

Qwen Code is a coding agent for terminal and IDE. You can use Claude Code with Generative APIs using Scaleway credentials and URL.

<Message type="tip">
  Refer to our dedicated documentation for [integrating Generative APIs into Qwen Code](/generative-apis/reference-content/integrate-with-qwen-code/)
</Message>

## Bolt.diy (code generation)

Bolt.diy is a software enabling users to create web applications from the prompt.

1. Install and launch Bolt.diy locally. Follow the setup instructions provided in the [Bolt.diy GitHub repository](https://github.com/stackblitz-labs/bolt.diy?tab=readme-ov-file#setup).
2. Once Bolt.diy is running, open the interface in your web browser.
3. Click the icon next to the Bolt logo to display the sidebar.
4. Click the cogwheel icon in the sidebar's bottom left corner to open the **Settings**.
5. Click **Local Providers** to add a new external provider configuration.
6. Toggle the switch next to **OpenAILike** to enable it. Then, enter the Scaleway API endpoint: `https://api.scaleway.ai/v1` as the base URL.
7. In Bolt's main menu, select `OpenAILike` and input your **Scaleway Secret Key** as the `OpenAILike API Key`.
8. Select one of the supported models from Scaleway Generative APIs. For best results with Bolt.diy, which requires a significant amount of output tokens (8000 by default), start with the `gemma-3-27b-it` model.
9. Enter your prompt in the Bolt.diy interface to see your application being generated.

<Message type="important">
    Only models that have a maximum output token of at least 8000 tokens are supported. Refer to the [list of Generative APIs models](/generative-apis/reference-content/supported-models/#chat-models) for more information.
</Message>

Alternatively, you can also setup your Scaleway Secret Key by renaming `.env.example` to `.env`, adding corresponding environment variables values and restarting Bolt.diy:
```bash
OPENAI_LIKE_API_BASE_URL=https://api.scaleway.ai/v1
OPENAI_LIKE_API_KEY=###SCW_SECRET_KEY###
```

To enable configuration from `.env` is taken into account, you still need to enable **OpenAILike** from Bolt interface in **Settings > Local Providers** section.
<Message type="note">
  If you first configured your credentials through the browser, you also need to reset your browser's cookies for your localhost domain (as Bolt.diy stores model provider configuration information in the browser).
</Message>

<Message type="tip">
  If you want to limit access to a specific Scaleway Project, replace API endpoint with `https://api.scaleway.ai/###PROJECT_ID###/v1/` since the default URL `https://api.scaleway.ai/v1/` can only be used with the default project.
</Message>

## Chatbox AI

Chatbox AI is a powerful AI client and smart assistant, compatible with Scaleway's Generative APIs service. It is available across multiple platforms, including Windows, macOS, Android, iOS, Web, and Linux.

<Message type="tip">
  Refer to our dedicated documentation for [installing and configuring Chatbox AI with Generative APIs](/tutorials/configure-chatboxai-with-generative-apis/)
</Message>

## n8n

n8n is an open-source workflow automation tool that allows users to build automated workflows by connecting various AI agents, apps, and services. It provides a visual interface to facilitate the creation of workflows.

<Message type="tip">
  Refer to our dedicated documentation for [integrating Generative APIs into n8n workflows](/generative-apis/reference-content/integrate-with-n8n/)
</Message>

## Custom HTTP integrations

You can interact with Scaleway's Generative APIs directly using any HTTP client.

### cURL example

To use cURL with Scaleway's Generative APIs, you can use the following command:
```bash
curl https://api.scaleway.ai/v1/chat/completions \
  -H "Authorization: Bearer <API secret key>" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.1-8b-instruct",
    "messages": [{"role": "user", "content": "What is quantum computing?"}]
  }'
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Python HTTP example

To perform HTTP requests with Scaleway's Generative APIs, install the `requests` dependency:
```bash
pip install requests
```

Then, you can use the following code:
```python
import requests
headers = {
    "Authorization": "Bearer <API secret key>",
    "Content-Type": "application/json"
}
data = {
    "model": "llama-3.1-8b-instruct",
    "messages": [{"role": "user", "content": "Explain black holes"}]
}
response = requests.post("https://api.scaleway.ai/v1/chat/completions", json=data, headers=headers)
print(response.json()["choices"][0]["message"]["content"])
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>
