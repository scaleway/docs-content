---
title: Adding AI to IntelliJ IDEA using Continue and Generative APIs
description: Learn how to integrate AI-powered code models into IntelliJ IDEA with Continue and Scaleway's Generative APIs.
tags: generative-apis ai machine-learning language-models code-assistance intellij-idea continue
dates:
  validation: 2025-02-14
  posted: 2025-02-14
---
import Requirements from '@macros/iam/requirements.mdx'


AI-driven coding is revolutionizing software development by automating repetitive tasks, generating code snippets, improving code quality, and identifying potential bugs. 
By integrating AI-powered tools, developers can significantly enhance productivity and optimize workflows. 
This guide will help you integrate AI-powered code models into JetBrain's IntelliJ IDEA using Continue and Scaleway’s Generative APIs.

<Requirements />

- A Scaleway account logged into the [console](https://console.scaleway.com)
- [Owner](/iam/concepts/#owner) status or [IAM permissions](/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- A valid [API key](/iam/how-to/create-api-keys/) for API authentication
- Installed [IntelliJ IDEA](https://www.jetbrains.com/idea/) on your local machine.



You can install Continue from the [JetBrains marketplace](https://plugins.jetbrains.com/plugin/22707-continue):

1. Open IntelliJ IDEA and go to **Preferences/Settings** (`Ctrl+Alt+S` on Windows/Linux, `Cmd+,` on macOS).
2. Navigate to **Plugins**, then click **Marketplace**.
3. Search for **Continue** and click **Install**.
4. Restart IntelliJ IDEA after installation.

## Configure Continue to use Scaleway’s Generative APIs

### Configure Continue through the graphical interface

To link Continue with Scaleway's Generative APIs, you can use built-in menus from Continue in IntelliJ IDEA.

- Click **Continue** in the menu on the right. .
- In the prompt section, click on **Select model** dropdown, then on **Add Chat model**.
- Select **Scaleway** as provider.
- Select the model you want to use (we recommend `Qwen 2.5 Coder 32b` to get started with chat and autocompletion only).
- Enter your **Scaleway secret key**.
    <Message type="tip">
     To start with, we recommend you use a Scaleway secret key having access to your `default` Scaleway project.
    </Message>

These actions will automatically edit your `config.yaml` file. To edit it manually, see [Configure Continue through configuration file](#configure-continue-through-configuration-file).

<Message type="note">
  Agents, embeddings and autocomplete models are not yet supported through graphical interface configuration. To enable them, you need to edit the configuration manually, see [Configure Continue through configuration file](#configure-continue-through-configuration-file).
</Message>

### Configure Continue through configuration file

To link Continue with Scaleway’s Generative APIs, you need to configure the settings file:

- Open your `config.yaml` settings file:
  - If you have already configured a **Local Assistant**, click **Local Assistant** then click the **wheel icon** to open your existing `config.yaml`
  - Otherwise, create a `config.yaml` file inside your `.continue` directory.
- Add the following configuration to enable Scaleway's Generative API. This configuration uses three different models for each tasks: 
  - `devstral-small-2505` for agentic workflows through chat interface
  - `qwen2.5-coder-32b` for autocompletion when editing a file
  - `bge-multilingual-gemma2`for embedding and retrieving code context
    ```yaml
    name: Continue Config
    version: 0.0.1
    models:
      - name: Devstral - Scaleway
        provider: openai
        model: devstral-small-2505
        apiBase: https://api.scaleway.ai/v1/
        apiKey: ###SCW_SECRET_KEY###
        defaultCompletionOptions:
          maxTokens: 8000
          contextLength: 50000
        roles:
          - chat
          - apply
          - embed
          - edit
        capabilities:
          - tool_use
      - name: Autocomplete - Scaleway
        provider: openai
        model: qwen2.5-coder-32b
        apiBase: https://api.scaleway.ai/v1/
        apiKey: ###SCW_SECRET_KEY###
        defaultCompletionOptions:
          maxTokens: 8000
          contextLength: 50000
        roles:
          - autocomplete
      - name: Embeddings Model - Scaleway
        provider: openai
        model: bge-multilingual-gemma2
        apiBase: https://api.scaleway.ai/v1/
        apiKey: ###SCW_SECRET_KEY###
        roles:
          - embed
        embedOptions:
          maxChunkSize: 256
          maxBatchSize: 32
    context:
      - provider: problems
      - provider: tree
      - provider: url
      - provider: search
      - provider: folder
      - provider: codebase
      - provider: web
        params:
          n: 3
      - provider: open
        params:
          onlyPinned: true
      - provider: docs
      - provider: terminal
      - provider: code
      - provider: diff
      - provider: currentFile
    ```
- Save the file at the correct location:
  - Linux/macOS: `~/.continue/config.yaml`
  - Windows: `%USERPROFILE%\.continue\config.yaml`
- In **Local Assistant**, click on **Reload config** or restart IntelliJ IDEA.

Alternatively, a `config.json` file can be used with the following format. This format is however deprecated, and we recommend using `config.yaml` instead.
```json
{
  "models": [
    {
      "model": "devstral-small-2505",
      "title": "Devstral - Scaleway",
      "provider": "openai",
      "apiKey": "###SCW_SECRET_KEY###"
    }
  ],
  "embeddingsProvider": {
    "model": "bge-multilingual-gemma2",
    "provider": "openai",
    "apiKey": "###SCW_SECRET_KEY###"
  },
  "tabAutocompleteModel": {
    "model": "qwen2.5-coder-32b",
    "title": "Autocomplete - Scaleway",
    "provider": "openai",
    "apiKey": "###SCW_SECRET_KEY###"
  }
}
```


<Message type="tip">
  For more details on configuring `config.yaml`, refer to the [official Continue documentation](https://docs.continue.dev/reference).
  If you want to limit access to a specific Scaleway Project, you should add the field `"apiBase": "https://api.scaleway.ai/###PROJECT_ID###/v1/"` for each model (ie. `models`, `embeddingsProvider` and `tabAutocompleteModel`) since the default URL `https://api.scaleway.ai/v1/` can only be used with the `default` project.
</Message>

## Activate Continue in IntelliJ IDEA

After configuring the API, activate Continue in IntelliJ IDEA:

- Open the **Command Search** (Press`Shift` twice quickly on Windows/Linux/macOS).
- Type `"Continue"` and select the appropriate command to enable AI-powered assistance.

<Message type="important">
  Enabling tab completion **may lead to higher token consumption** as the model generates predictions for every keystroke. Be mindful of your API usage and adjust settings accordingly to avoid unexpected costs. For more information, refer to the [official Continue documentation](https://docs.continue.dev/reference#tabautocompleteoptions).
</Message>

## Going further

You can add additional parameters to configure your model behaviour by editing `config.yaml`.
For instance, you can add the following `chatOptions.baseSystemMessage` value to modify LLM messages `"role":"system"` and/or `"role":"developer"` and provide less verbose answers:
```yaml
model:...
chatOptions:
  baseSystemMessage: "You are an expert developer. Only write concise answers."
```
