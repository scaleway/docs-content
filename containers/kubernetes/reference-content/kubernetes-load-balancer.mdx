---
meta:
  title: Creating and configuring a Load Balancer service
  description: This page provides information about creating and configuring a Load Balancer service for your Kubernetes cluster
content:
  h1: Creating and configuring a Load Balancer service
  paragraph: This page provides information about creating and configuring a Load Balancer service for your Kubernetes cluster
tags: kubernetes load-balancer loadbalancer service annotations ip expose
dates:
  validation: 2024-04-29
  posted: 2023-10-25
categories:
  - kubernetes
---

Creating a Load Balancer for your Kubernetes cluster allows you to expose an application running inside your cluster to the internet.

In this document, we summarize when to create a Load Balancer for your cluster (as opposed to a different solution for exposing your application), and take you through the basic steps to create and configure your Load Balancer.

## Does your cluster need a Load Balancer?

Before creating a Load Balancer for your cluster, ensure that this is definitely the best solution for what you want to achieve.

A  single **LoadBalancer** Service is sufficient for exposing one service in your cluster. Each further service will need its own external Load Balancer (which should generally be set up to forward TCP traffic) and corresponding `LoadBalancer` Service.

However, remember that Load Balancers are a paid-for resource. Consider whether one of the following free solutions might be appropriate if you have a relatively simple cluster:

- A **ClusterIP** Service is sufficient for facilitating communication between different components in a cluster.
- A **NodePort** Service is often sufficient for exposing a single application in a simple cluster, to the internet for testing purposes.

On the other hand, if you have multiple services running in a more complex cluster, and you want to forward traffic to the right service based on HTTP, consider the following:

- **Ingress** with an **ingress controller** and **Load Balancer** may be more suitable for exposing multiple services in your cluster, via a single external IP which forwards HTTP traffic to the right service in the cluster based on Ingress rules.

Read the [full documentation](/containers/kubernetes/reference-content/exposing-services/) on different ways to expose your services for full details, and links to the relevant documentation for each possibility.

## Creating a Load Balancer for your cluster: overview

Here is a quick overview of how to create a Load Balancer for your cluster:

- [Create a Scaleway Kubernetes Kapsule cluster](/network/load-balancer/how-to/create-load-balancer/) with an application running inside.
- Make sure you have [installed and configured kubectl](/containers/kubernetes/how-to/connect-cluster-kubectl/)
- Create a yaml manifest to describe the LoadBalancer service you want to create. You can use [Load Balancer annotations](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md/) to fine-tune the Load Balancer's configuration in the manifest.
- Deploy the LoadBalancer service based on the manifest, using kubectl. The Cloud Controller Manager (CCM) will spin up the external [Scaleway Load Balancer](/network/load-balancer/quickstart/) with the correct configuration to forward traffic to the LoadBalancer service within your cluster.
- Modify your Load Balancer's configuration as necessary via the yaml manifest and [Load Balancer annotations](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md/) , putting any new annotations into effect via kubectl, so the CCM can carry out the modifications as necessary.

<Message type="important">
Load Balancers for Kubernetes clusters should **always** be provisioned via the cluster's Cloud Controller Manager. It is **not** correct procedure to provision the Load Balancer by creating a Scaleway Load Balancer in the console or via the API, and then attempting to use it as your cluster's external Load Balancer. Similarly, you cannot use the Scaleway console or devtools to edit your cluster's Load Balancer after creation, this must be done via the CCM, as detailed in this documentation.
</Message>

## Creating a Load Balancer for your cluster: step by step

<Macro id="requirements" />

- A Scaleway account logged into the [console](https://console.scaleway.com/)
- [Owner](/identity-and-access-management/iam/concepts/#owner) status or [IAM permissions](/identity-and-access-management/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- [Created a Kubernetes Kapsule cluster](/network/load-balancer/how-to/create-load-balancer/)
- [Installed and configured kubectl](/containers/kubernetes/how-to/connect-cluster-kubectl/)
- An application running in your cluster

You can refer to the [following example of webserver application to run.](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-examples.md/)

1. Create a `.yaml` file to hold the manifest for your cluster's Load Balancer. This will describe the resource (Load Balancer) that you want to create.

        Below, find an example for the content of the yaml manifest. You will need to edit it to your own specifications.

        ```yaml
        apiVersion: v1
        kind: Service
        metadata:
        name: myloadbalancer
        spec:
        type: LoadBalancer
        ports:
        - port: 8000
            name: http
            targetPort: 8000
        selector:
            app: mydeployment
        ```

        - `apiVersion`: which version of the Kubernetes API to use to create the object
        - `kind`: the kind of object defined in this YAML file. For a Load Balancer, specify a `Service`
        - `metadata`: helps uniquely identify the Service object: give it a `name` (e.g. `myloadbalancer`).
        - `spec`: specifies the Service:
            - `type`: the type of Service required: a `LoadBalancer` Service.
            - `ports`: the ports for the Service configuration. You can define many ports if you want, here we specify just one:
            - `port`: the new service port that will be created, for connecting to the application
            - `name`: a name for this port, e.g. `http`
            - `targetPort`: the application port to target with requests coming from the Service
            - `selector`: links the LoadBalancer Service with a set of pods in the cluster. Ensure that the `app` specified matches the name of the deployment of your app in the cluster (run `kubectl get all` if necessary to check the name).

2. Use the command `kubectl create -f <name-of-manifest-file>.yaml` to tell the Kubernetes Cloud Controller to create the Load Balancer from the manifest in the default namespace.

3. Run `kubectl get svc` to confirm that the Load Balancer Service has been created, and view its external IP. You can also check the [Load Balancer](https://console.scaleway.com/load-balancer/) section of the Scaleway console, where your Kuberenetes cluster's Load Balancer now appears. Note that you should **not** attempt to edit or delete the Load Balancer via the console, only via the manifest file and kubectl.

## Specifying an IP address for your Load Balancer

By default, when you create a Load Balancer for your cluster, it will be assigned a public IP address at random. When you delete the Load Balancer, the IP address will also be deleted, and cannot be retrieved to transfer to another Load Balancer service in your cluster.

However, it is possible to use [flexible IP addresses](/network/load-balancer/concepts/#flexible-ip-address) with your cluster's Load Balancer, to give you more control over the IPs being used. Flexible IP addresses can be kept in your account even if/when their associated Load Balancer is deleted. They can then be assigned to a new Load Balancer in the future.

To specify that an existing flexible IP address that you hold in your account should be used when creating your Load Balancer, add the `loadBalancerIP` field to your yaml manifest, as shown in the last line here:


    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
    name: myloadbalancer
    spec:
    type: LoadBalancer
    ports:
    - port: 8000
        name: http
        targetPort: 8000
    selector:
        app: mydeployment
    loadBalancerIP: 51.159.24.7
    ```

For full details and further examples of how to use flexible IPs with your Kubernetes Load Balancer, see our [dedicated documentation](/containers/kubernetes/reference-content/managing-load-balancer-ips/).

## Defining your Load Balancer's configuration via annotations

Your Load Balancer will be created with a default configuration unless you define configuration parameters via **annotations**.

With annotations, you can configure parameters such as the balancing method, health check settings, and more.

<Message type="important">
You should **never** try to modify the configuration of your cluster's Load Balancer via the Scaleway console, the API, or any other devtools. Any modifications made this way will be overwritten by the cluster's CCM. You should **always** use annotations as described below to configure your cluster's Load Balancer.
</Message>

Add annotations to the `metadata` section of your LoadBalancer Service's yaml manifest as shown below. In this example we include two annotations, but you can include as many as you need.

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: myloadbalancer
      annotations:
        service.beta.kubernetes.io/scw-loadbalancer-forward-port-algorithm: "leastconn"
        service.beta.kubernetes.io/scw-loadbalancer-health-check-delay: "10s"
    spec:
      type: LoadBalancer
      ports:
      - port: 8000
        name: http
        targetPort: 8000
      selector:
        app: mydeployment
    ```

For full details on how to use Load Balancer annotations when creating your Load Balancer, or how to modify your Load Balancer's annotations after creation, see our [dedicated documentation](/containers/kubernetes/reference-content/using-load-balancer-annotations/). For a full list of Load Balancer annotations, refer to the [Scaleway Cloud Controller documentation](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md/).

## Troubleshooting Kubernetes Load Balancers

### Load Balancer certificate error using SSL offload

If your Load Balancer is configured for [SSL offload](/network/load-balancer/reference-content/ssl-bridging-offloading-passthrough/#configuring-a-load-balancer-for-ssl-offloading), and you have several services behind the same Load Balancer, you will encounter an SSL error when trying to reach the other services using HTTPS.

Example:
- podA
- podB (`https://serviceB.example.com`)

From podA, a curl to `https://serviceB.example.com` will result in an SSL error.

To force the Load Balancer to handle all requests using the SSL offload, enable the [use hostname annotations](https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md#servicebetakubernetesioscw-loadbalancer-use-hostname/) on your Load Balancer service.

### Load Balancer TCP Proxy and Nginx Ingress error 400

If your Load Balancer is configured using TCP Proxy and you are using an Nginx Ingress, you might encounter an HTTP 400 error.

The Nginx Ingress must be configured with [use-proxy-protocol](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-proxy-protocol) to accept TCP Proxy requests.

#### Nginx Ingress Easy Deploy

The [Easy Deploy](/containers/kubernetes/how-to/enable-easy-deploy) Nginx Ingress can be configured to accept TCP Proxy:
```
controller:
  service:
    annotations:
      service.beta.kubernetes.io/scw-loadbalancer-proxy-protocol-v2: "true"
      service.beta.kubernetes.io/scw-loadbalancer-use-hostname: "true"
  config:
    use-forwarded-headers: true
    compute-full-forwarded-for: true
    use-proxy-protocol: true
```

## Further resources

For more help and support using Scaleway Load Balancers with your Kubernetes cluster, check out the following resources:

- [Scaleway Load Balancers: full documentation](https://www.scaleway.com/en/docs/network/load-balancer/) *
- [Getting Started with Kubernetes Load Balancers - Tutorial](/tutorials/get-started-kubernetes-loadbalancer/)
- [Getting Started with Kubernetes Load Balancers - Video Demonstration](https://www.youtube.com/watch?v=W3gPUQ_ELEo/)
- [Configuring a Load Balancer for your Kubernetes applications - Webinar](https://www.youtube.com/watch?v=V0uKqYXJRF4/)
- [Managing Kubernetes Load Balancer IPs](/containers/kubernetes/reference-content/managing-load-balancer-ips/)
- [Using annotations for Kubernetes Load Balancers](/containers/kubernetes/reference-content/using-load-balancer-annotations/)

\* Though this documentation may be useful, bear in mind that it principally concerns Load Balancers outside a Kubernetes context. Remember to always create and configure Load Balancers for your Kubernetes cluster via the methods described on this page and **not** via the Scaleway console, API, or developer tools.