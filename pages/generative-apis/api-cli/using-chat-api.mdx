---
title: Using Chat API
description: This page explains how to use the Chat API to query models
tags: generative-apis ai-data chat-api
dates:
  validation: 2025-09-22
  posted: 2024-09-03
---

Scaleway Generative APIs are designed as a drop-in replacement for the OpenAI APIs. If you have an LLM-driven application that uses one of OpenAI's client libraries, you can easily configure it to point to Scaleway Chat API, and get your existing applications running using open-weight instruct models hosted at Scaleway.

<Message type="note">
You can also try the **Responses** API for LLM-driven tasks. Released in 2025, it is designed to combine the simplicity of Chat Completions with the ability to do more agentic tasks and reasoning. Scaleway's support for the Responses API is currently at beta stage. [Find out more about the Responses API](/generative-apis/how-to/query-language-models/#chat-completions-api-or-responses-api).
</Message>

## Create chat completion

Creates a model response for the given chat conversation.

**Request sample:**

```
curl --request POST \
     --url https://api.scaleway.ai/v1/chat/completions \
     --header 'Authorization: Bearer ${SCW_SECRET_KEY}' \
     --header 'Content-Type: application/json' \
     --data '{
     "model": "llama-3.1-8b-instruct",
     "messages": [
      {
        "role": "system",
        "content": "<string>"
      },
      {
        "role": "user",
        "content": "<string>"
      }
     ],
     "max_tokens": integer,
     "temperature": float,
     "top_p": float,
     "presence_penalty": float,
     "stop": "<string>",
     "stream": boolean,
     }'
```


## Headers

Find required headers in [this page](/generative-apis/api-cli/using-generative-apis/).

## Body

### Required parameters

| Param  | Type | Description |
| ------------- |-------------|-------------|
| **messages**     | array of objects     | A list of messages comprising the conversation so far.     |
| **model**      | string     | The name of the model to query.     |

Our chat API is OpenAI compatible. Use OpenAIâ€™s [API reference](https://platform.openai.com/docs/api-reference/chat/create) for more detailed information on the usage.

### Supported parameters

- temperature
- top_p
- max_tokens
- stream
- stream_options
- presence_penalty
- [response_format](/generative-apis/how-to/use-structured-outputs)
- logprobs
- stop
- seed
- [tools](/generative-apis/how-to/use-function-calling)
- [tool_choice](/generative-apis/how-to/use-function-calling)

### Unsupported parameters

- frequency_penalty
- n
- top_logprobs
- logit_bias
- user

If you have a use case requiring one of these unsupported parameters, please [contact us via Slack](https://slack.scaleway.com/) on #ai channel.

## Going further

1. [Python code examples](/generative-apis/how-to/query-language-models/#querying-language-models-via-api) to query text models using Scaleway's Chat API
2. [How to use structured outputs](/generative-apis/how-to/use-structured-outputs) with the `response_format` parameter
3. [How to use function calling](/generative-apis/how-to/use-function-calling) with `tools` and `tool_choice`