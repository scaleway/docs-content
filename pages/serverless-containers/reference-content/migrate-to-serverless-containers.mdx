---
title: How to migrate your workloads to Scaleway Serverless Containers
description: This page gives recommendations and steps to migrate your workloads from Kubernetes or conventional virtual machines to Scaleway Serverless Containers
tags: migration switch change adopt serverless containers go serverless try k8s vm
dates:
  validation: 2025-08-27
  posted: 2025-08-27
products:
  - serverless-containers
difficulty: beginner
usecase:
  - migration
ecosystem:
  - scaleway
---

This guide is designed for developers and operators who are currently running workloads on Kubernetes or traditional virtual machines, and are considering a migration to [Serverless Containers](/serverless-containers/concepts/#serverless-containers).

This guide covers the [core concepts](#why-migrate-to-serverless-containers) of Serverless Containers, the [operational benefits](#key-features) of this model, and a [practical path](#quick-deployment-guide) for migration.

## Why migrate to Serverless Containers

Moving to a Serverless Containers model involves a shift in operational responsibility from you to the cloud provider. This change brings several key advantages for development teams.

**Reduced operational overhead**

The primary benefit is the abstraction of the underlying infrastructure. You do not need to provision, manage, scale, or patch servers, operating systems, or container orchestration platforms like Kubernetes. This allows your team to focus on application logic rather than infrastructure management.

**Container-based workflow**

You can continue to use the standard container-based development workflow. Packaging your application and its dependencies into a container image ensures a consistent and reproducible environment, from local development to production.

**Stateless architecture**

Serverless Containers are designed for stateless services. This architectural pattern promotes building applications that are horizontally scalable and resilient, as any instance can handle any request without relying on local state.

**Efficient resource consumption**

The platform automatically scales the number of running container instances based on request volume, CPU consumption or RAM usage. This removes the need to manually configure and tune autoscaling rules, ensuring your application has the resources it needs to meet demand. For services with variable or infrequent traffic, this model is highly efficient, as resources can scale down to zero when there are no requests, eliminating the cost of idle capacity.

Refer to our [dedicated overview page](/serverless-containers/reference-content/serverless-overview/) for general information on Scaleway's Serverless products.

## Key features

Serverless Containers come packed with features designed for modern application development.

- **Private Networks compatibility**: Securely connect your services to other resources within your Virtual Private Cloud.
    - Learn [how to use Private Networks with Serverless Containers](/serverless-containers/reference-content/containers-private-networks/).

- **Custom domains**: Easily map your own domain names to your services.
    - Discover [how to add custom domains to Serverless Containers](/serverless-containers/how-to/add-a-custom-domain-to-a-container/).

- **Healthchecks**: Configure readiness and liveness probes to ensure your application instances are healthy and ready to serve traffic.
    - Get [information about healtchecks](/serverless-containers/concepts/#health-check).

- **Built-in monitoring**: Gain immediate insights on your application's performance with integrated logging and metrics, without needing to set up complex monitoring agents.
    -  Check [how to monitor your Serverless Container](/serverless-containers/how-to/monitor-container/).

- **Enhanced security**: Because the platform is managed by Scaleway, it benefits from continuous security patching and best practices, reducing your operational security burden.
    - Find out [how to secure a Serverless Container](/serverless-containers/how-to/secure-a-container/).

To dive deeper into Serverless Containers, refer to the dedicated [concepts page](/serverless-containers/concepts/).

## Quick deployment guide

Deploying your first service to Serverless Containers is straightforward. Hereâ€™s a high-level overview of the steps.

1. **Containerize your application**: If you haven't already, package your application into a container image using a Dockerfile.

2. **Push your image to a registry**: Follow the [dedicated Quickstart documentation](/container-registry/quickstart/) to discover how to log in to the Scaleway Container Registry and store your images.

3. **Deploy your container**: Read the [How to deploy a container](/serverless-containers/how-to/deploy-container/) page to create your container using the Scaleway console.

4. **Click Deploy**: The Scaleway platform will pull your container image and run it. Within a few minutes, your Serverless Container will be publicly accessible via its HTTPS endpoint.

## Best practices for migration

Migrating existing applications from Kubernetes or Instances to Serverless Containers is an opportunity to modernize your architecture.

### General best practices

**Containerize everything**

Your application must be packaged as a container image. This is the fundamental deployment unit for Serverless Containers.

**Embrace statelessness**

Since Serverless Containers are stateless, you cannot rely on the local filesystem for storing data that needs to persist between requests.

**Use external storage**

To store data, you can use [Scaleway Object Storage](/object-storage/), [Scaleway Managed Databases](/managed-databases-for-postgresql-and-mysql/), and [Scaleway Serverless Databases](/serverless-sql-databases/).

**Externalize state**

For application state, use a managed database, cache like [Redis](/managed-databases-for-redis/how-to/create-a-database-for-redis/) or [message queues](/queues/quickstart/).

**Manage your infrastructure as code**

While you can manage your services through the Scaleway console, we highly recommend using developer tools for a repeatable and version-controlled setup.

**CLI**

Use the [Scaleway command-line interface](/scaleway-cli/quickstart/) for easy resource management, scripting, and automation.

**Terraform/IaC**

Define your Serverless Containers services using tools like Terraform or OpenTofu via the [Scaleway Provider](/terraform/quickstart/) for a fully automated and declarative infrastructure.

### Migration strategies

**Progressive migration**

You do not need to migrate your entire application at once. Serverless Containers are perfect for microservices. You can start by migrating a single, smaller service to get a feel of the platform. This approach minimizes risk and allows your teams to learn as they go.

**API migration**

When migrating an API, you can create a new version of your API on Serverless Containers. For example, you can create a new `/v2/` endpoint for your API that is served by Serverless Containers, while the existing `/v1/` remains on your current infrastructure. This allows for a gradual rollout to your users.

### Start small with Serverless Jobs

If you are looking for an even simpler way to start your Serverless journey, consider using Serverless Jobs. This is a companion product designed for running autonomous batch jobs, scripts, or automated tasks that run to completion.

Instead of migrating a full web service, you can start by offloading a small automation task (like a nightly data processing script) to a Serverless Job. This is a low-risk way to familiarize your team with the Serverless Container ecosystem before committing to migrating larger, more critical services.

Refer to the [Serverless Jobs quickstart guide](/serverless-jobs/quickstart/) to deploy your first job in a few minutes.
