---
title: Supported models
description: This page lists which open-source chat or embedding models Scaleway is currently hosting
tags: generative-apis ai-data supported-models
dates:
  validation: 2025-02-14
  posted: 2024-09-02
---

Our API supports the most popular models for [Chat](/generative-apis/how-to/query-language-models), [Vision](/generative-apis/how-to/query-vision-models/) and [Embeddings](/generative-apis/how-to/query-embedding-models/).

## Multimodal models (chat and vision)

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Google (Preview)   | `gemma-3-27b-it`  | 40k  | 8192 | [Gemma](https://ai.google.dev/gemma/terms) | [HF](https://huggingface.co/google/gemma-3-27b-it) |
| Mistral | `mistral-small-3.1-24b-instruct-2503`  | 128k  | 8192 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503) |

## Chat models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Meta        | `llama-3.3-70b-instruct`  | 100k  | 4096 | [Llama 3.3 Community](https://www.llama.com/llama3_3/license/) | [HF](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) |
| Meta        | `llama-3.1-8b-instruct`  | 128k  | 16384 | [Llama 3.1 Community](https://llama.meta.com/llama3_1/license/) | [HF](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) |
| Mistral      | `mistral-nemo-instruct-2407`   | 128k | 8192 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407) |
| Qwen      | `qwen2.5-coder-32b-instruct`     | 32k | 8192 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct) |
| DeepSeek (Preview)  | `deepseek-r1`     | 20k | 4096 | [MIT](https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/mit.md) | [HF](https://huggingface.co/deepseek-ai/DeepSeek-R1) |
| DeepSeek  | `deepseek-r1-distill-llama-70b`     | 32k | 4096 | [MIT](https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/mit.md) | [HF](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B) |

<Message type="note">
  DeepSeek-R1 is currently under maintenance and therefore not available on Generative APIs anymore.
</Message>

<Message type="tip">
  If you are unsure which chat model to use, we currently recommend Llama 3.1 8B Instruct (`llama-3.1-8b-instruct`) to get started.
</Message>

## Vision models

| Provider | Model string | Context window (Tokens) | Maximum output (Tokens)| License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Mistral      | `pixtral-12b-2409`    | 128k | 4096 | [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) | [HF](https://huggingface.co/mistralai/Pixtral-12B-2409) |

<Message type="note">
  Image sizes are limited to 32 million pixels (e.g., a resolution of about 8096 x 4048). Images with a resolution higher than 1024 x 1024 are supported, but automatically downscaled to fit these limitations (image ratio and proportions will be preserved).
</Message>

## Embedding models

Our [Embeddings API](/generative-apis/how-to/query-embedding-models) provides built-in support for the following models, hosted in Scaleway data centers, available via serverless endpoints.

| Provider | Model string | Model size | Embedding dimension | Context window |  License | Model card |
|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| BAAI        | `bge-multilingual-gemma2`  | 9B  | 3584 | 4096 | [Gemma](https://ai.google.dev/gemma/terms) | [HF](https://huggingface.co/BAAI/bge-multilingual-gemma2) |

## Request a model

**Do not see a model you want to use?** [Tell us or vote for what you would like to add here.](https://feature-request.scaleway.com/?tags=ai-services)

## Deprecated models

These models can still be accessed in Generative APIs, but their End of Life (EOL) is planned according to our [model lifecyle policy](/generative-apis/reference-content/model-lifecycle/).
Deprecated models should not be queried anymore. We recommend to use newer models available in Generative APIs or to deploy these models in dedicated [Managed Inference](https://console.scaleway.com/inference/deployments) deployments.

| Provider | Model string | End of Life (EOL) date 
|-----------------|-----------------|-----------------|
| Meta    | `llama-3.1-70b-instruct` | 25th May, 2025 |

<Message type="note">
    Llama 3.1 70B is now deprecated. The new Llama 3.3 70B is available with similar or better performance in most use cases.
After May 25th 2025, your requests to Llama 3.1 70B will be redirected automatically to Llama 3.3 70B. Llama 3.1 8B is not affected by this change and remains supported.
</Message>

## End of Life (EOL) models

These models are not accessible anymore from Generative APIs. They can still however be deployed on dedicated [Managed Inference](https://console.scaleway.com/inference/deployments) deployments.

| Provider | Model string | EOL date 
|-----------------|-----------------|-----------------|
| SBERT      | `sentence-t5-xxl`  | 26 February, 2025 |
