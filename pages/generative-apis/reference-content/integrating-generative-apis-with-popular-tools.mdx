---
meta:
  title: Integrating Scaleway Generative APIs with popular AI tools
  description: Learn how to integrate Scaleway's Generative APIs with popular AI tools to unlock the full potential of your applications.
content:
  h1: Integrating Scaleway Generative APIs with popular AI tools
  paragraph: Scaleway's Generative APIs provide a powerful way to integrate AI capabilities into your applications. By leveraging our APIs, you can tap into the latest advancements in natural language processing, computer vision, and more. In this guide, we'll show you how to integrate Scaleway's Generative APIs with popular AI tools like LangChain, LlamaIndex, and OpenAI.
tags: generative-apis, ai, language-models
dates:
  validation: 2025-02-18
  posted: 2025-02-18
---

Scaleway's Generative APIs are designed to provide easy access to the latest AI models and techniques. Our APIs are built on top of a robust infrastructure that ensures scalability, reliability, and security. With our APIs, you can integrate AI capabilities into your applications, such as text generation, image classification, and more.

## Comparison of AI tools and libraries

The following table compares AI tools and libraries supported by Scaleway's Generative APIs:

| Tool/Library | Description | Use cases | Integration effort |
| --- | --- | --- | --- |
| [OpenAI](#openai-compatible-libraries) | Popular AI library for natural language processing | Text generation, language translation, text summarization | Low |
| [LangChain](#langchain-rag-and-llm-applications) | Library for building AI applications | Inference, embeddings, document indexing and retrieval | Medium |
| [LlamaIndex](#llamaindex-document-indexing-and-retrieval) | Library for indexing and retrieving documents using AI models | Document indexing and retrieval, question answering | Medium |
| [Continue Dev](#continue-dev-ai-coding-assistance) | Library for AI-powered coding assistance | Code completion, code review | Low |
| [Transformers (Hugging Face)](#transformers-hugging-face-integration) | Library for pre-trained models for natural language processing | Text generation, language translation, text summarization | Medium |
| [cURL/Python](#api-clients-and-custom-integrations) | Direct API clients for custom integrations | Custom applications, data processing | High |

<Message type="note">
  The integration effort is subjective and may vary depending on the specific use case and requirements.
</Message>

## OpenAI-compatible libraries

Scaleway Generative APIs follow OpenAI's API structure, making integration straightforward. To get started, you'll need to install the OpenAI library and set up your API key.

### Configuration

To use the OpenAI client library with Scaleway's Generative APIs, you'll need to install the required dependencies:
```bash
pip install openai
```

Then you'll need to set the API key and base URL in your OpenAI-compatible client:
```python
from openai import OpenAI
client = OpenAI(
    base_url="https://api.scaleway.ai/v1",
    api_key="<API secret key>"
)
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Using OpenAI client for text generation

To use OpenAI client for text generation, you can create a `ChatCompletion` object and call the `create` method:
```python
response = client.chat.completions.create(
    model="llama-3.1-8b-instruct",
    messages=[{"role": "user", "content": "Tell me a joke about AI"}]
)
print(response.choices[0].message.content)
```

## LangChain (RAG & LLM applications)

LangChain is a popular library for building AI applications. Scaleway's Generative APIs support LangChain for both inference and embeddings.

<Message type="tip">
  Refer our dedicated documentation for
  - [Implementing Retrieval-Augmented Generation (RAG) with LangChain and Scaleway Generative APIs](/tutorials/how-to-implement-rag-generativeapis/)
</Message>

### Configuration

To use LangChain with Scaleway's Generative APIs, you'll need to install the required dependencies:
```bash
pip install langchain langchain_openai langchain_postgres psycopg2
```
Next, set up the API connection:
```python
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import os
os.environ["OPENAI_API_KEY"] = "<API secret key>"
os.environ["OPENAI_API_BASE"] = "https://api.scaleway.ai/v1"
llm = ChatOpenAI(model="llama-3.1-8b-instruct")
embeddings = OpenAIEmbeddings(model="bge-multilingual-gemma2")
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Using LangChain for inference

To use LangChain for inference, you can create a `ChatOpenAI` object and call the `ask` method:
```python
response = llm.ask("What is the capital of France?")
print(response)
```
### Using LangChain for embeddings

To use LangChain for embeddings, you can create an `OpenAIEmbeddings` object and call the `compute_embeddings` method:
```python
embeddings = OpenAIEmbeddings(model="bge-multilingual-gemma2")
text = "This is an example sentence."
embedding = embeddings.compute_embeddings(text)
print(embedding)
```
## LlamaIndex (document indexing & retrieval)

LlamaIndex is a library for indexing and retrieving documents using AI models. Scaleway's Generative APIs support LlamaIndex for document indexing and retrieval.

### Configuration

To use LlamaIndex with Scaleway's Generative APIs, you'll need to install the required dependencies:
```bash
pip install llama-index
```
Next, set up the embedding model:
```python
from llama_index.embeddings.openai import OpenAIEmbedding
embed_model = OpenAIEmbedding(
    api_key="<API secret key>",
    api_base="https://api.scaleway.ai/v1",
    model="bge-multilingual-gemma2"
)
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Indexing documents

To index documents using LlamaIndex, you'll need to create a `VectorStoreIndex` object and call the `add_documents` method:
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader
documents = SimpleDirectoryReader("data").load_data()
index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)
```
### Retrieving documents

To retrieve documents using LlamaIndex, you can call the `query` method on the `VectorStoreIndex` object:
```python
query_engine = index.as_query_engine()
response = query_engine.query("Summarize this document")
print(response)
```

## Continue Dev (AI coding assistance)

Continue Dev is a library that provides AI-powered coding assistance. Scaleway's Generative APIs support Continue Dev for code completion and more.

<Message type="tip">
  Refer our dedicated documentation for
  - [Integrating Continue Dev with Visual Studio Code](/generative-apis/reference-content/adding-ai-to-vscode-using-continue/)
  - [Integrating Continue Dev with IntelliJ IDEA](/generative-apis/reference-content/adding-ai-to-intellij-using-continue/)
</Message>

### Configuration

To use Continue Dev with Scaleway's Generative APIs, you'll need to modify the `continue.json` file to add Scaleway's API:
```json
{
  "models": [
    {
      "title": "Qwen2.5-Coder-32B-Instruct",
      "provider": "scaleway",
      "model": "qwen2.5-coder-32b-instruct",
      "apiKey": "<API secret key>"
    }
  ],
  "embeddingsProvider": {
    "provider": "scaleway",
    "model": "bge-multilingual-gemma2",
    "apiKey": "<API secret key>"
  },
  "tabAutocompleteModel": {
    "model": "qwen2.5-coder-32b",
    "title": "Qwen2.5 Coder Autocomplete",
    "provider": "scaleway",
    "apiKey": "<API secret key>"
  }
}
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

## Transformers (Hugging Face integration)

Hugging Face's `transformers` library provides a range of pre-trained models for natural language processing. Scaleway's Generative APIs support Hugging Face integration for text generation and more.

### Configuration

To use Hugging Face with Scaleway's Generative APIs, you'll need to install the `transformers` library and set up your API key:
```python
from transformers import pipeline
generator = pipeline(
    "text-generation",
    model="llama-3.1-8b-instruct",
    tokenizer="meta-llama/Llama-3-8b",
    api_base="https://api.scaleway.ai/v1",
    api_key="<API secret key>"
)
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Using Hugging Face for text generation

To use Hugging Face for text generation, you can call the `generator` function:
```python
print(generator("Write a short poem about the ocean"))
```
## API clients and custom integrations

You can interact with Scaleway's Generative APIs directly using any HTTP client.

### cURL example

To use cURL with Scaleway's Generative APIs, you can use the following command:
```bash
curl https://api.scaleway.ai/v1/chat/completions \
  -H "Authorization: Bearer <API secret key>" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.1-8b-instruct",
    "messages": [{"role": "user", "content": "What is quantum computing?"}]
  }'
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>

### Python example

To use Python with Scaleway's Generative APIs, you can use the following code:
```python
import requests
headers = {
    "Authorization": "Bearer <API secret key>",
    "Content-Type": "application/json"
}
data = {
    "model": "llama-3.1-8b-instruct",
    "messages": [{"role": "user", "content": "Explain black holes"}]
}
response = requests.post("https://api.scaleway.ai/v1/chat/completions", json=data, headers=headers)
print(response.json()["choices"][0]["message"]["content"])
```
<Message type="tip">
  Make sure to replace `<API secret key>` with your actual API key.
</Message>
