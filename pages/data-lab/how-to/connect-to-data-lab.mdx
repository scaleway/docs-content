---
title: How to connect to a Data Lab for Apache Spark™
description: Step-by-step guide to connecting to a Data Lab for Apache Spark™ with the Scaleway console.
tags: data lab for apache spark create process
dates:
  validation: 2025-02-24
  posted: 2024-07-31
---
import Requirements from '@macros/iam/requirements.mdx'


<Requirements />

- A Scaleway account logged into the [console](https://console.scaleway.com)
- [Owner](/iam/concepts/#owner) status or [IAM permissions](/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- Created a [Data Lab for Apache Spark™ cluster](/data-lab/how-to/create-data-lab/)
- A valid [API key](/iam/how-to/create-api-keys/)

1. Click **Data Lab** under **Data & Analytics** on the side menu. The Data Lab for Apache Spark™ page displays.

2. Click the name of the Data Lab cluster you want to connect to. The cluster **Overview** page displays.

3. Click **Open Notebook** in the **Notebook** section. You are directed to the notebook login page.

4. Enter your [API secret key](/iam/concepts/#api-key) when prompted for a password, then click **Log in**. You are directed to the lab's home screen.

5. In the files list on the left, double-click the `DatalabDemo.ipynb` file to open it.

6. Update the first cell of the file with your API access key and secret key, as shown below:

    ```json
    "spark.hadoop.fs.s3a.access.key": "[your-api-access-key]",
    "spark.hadoop.fs.s3a.secret.key": "[your-api-secret-key]",
    ```

    Your notebook environment is now ready to be used.

7. Optionally, follow the instructions contained in the `DatalabDemo.ipynb` file to process a test batch of data.