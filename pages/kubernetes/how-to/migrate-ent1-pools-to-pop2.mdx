---
meta:
  title: Migrating ENT1 pools to POP2 in your Kubernetes cluster
  description: A step-by-step guide to transitioning from ENT1 to POP2 Instances in Scaleway's Kubernetes Kapsule clusters, ensuring minimal disruption and optimal performance.
content:
  h1: Migrating ENT1 pools to POP2 in your Kubernetes cluster
  paragraph: A step-by-step guide to transitioning from ENT1 to POP2 Instances in Scaleway's Kubernetes Kapsule clusters, ensuring minimal disruption and optimal performance.
tags: kubernetes kapsule pop2 transition
dates:
  validation: 2025-01-24
  posted: 2025-01-24
categories:
  - containers
---

Scaleway is deprecating [production-optimized **ENT1** Instances](/instances/reference-content/production-optimized/). 
This guide provides a step-by-step process to migrate from **ENT1** Instances to **POP2** Instances within your Scaleway Kubernetes Kapsule clusters.

<Macro id="requirements" />

- A Scaleway account logged into the [Scaleway console](https://console.scaleway.com)
- [Owner](/iam/concepts/#owner) status or [IAM permissions](/iam/concepts/#permission) allowing actions in the intended Organization
- [Created](/kubernetes/how-to/create-cluster) a Kubernetes Kapsule or Kosmos cluster

## Identifying your ENT1 pools

1. Log in to the [Scaleway Console](https://console.scaleway.com).
2. Navigate to **Kubernetes** under the **Containers** section in the side menu of the console.
3. From the drop-down menu, select the geographical region you want to manage.
4. Select the cluster containing the ENT1 pools you intend to migrate.
5. In the **Pools** tab, identify and note the pools using **ENT1** Instances.

## Creating equivalent POP2 pools

1. For each ENT1 pool identified:
   - Click **+ Create pool** (or **Add pool**).
   - Select **POP2** from the **Node Type** dropdown menu.
   - Configure the pool settings (e.g., Availability Zone, size, autoscaling, autoheal) to mirror the existing ENT1 pool as closely as possible.
   - Click **Create** (or **Add pool**) to initiate the new pool.

2. Monitor the status of the new POP2 nodes until they reach the **Ready** state:
   - In the **Pools** tab of the console.
   - Alternatively, use `kubectl` with the command:
     ```
     kubectl get nodes
     ```
     Ensure all POP2 nodes display a **Ready** status.

<Message type="tip">
  It is recommended to perform these steps during a maintenance window or periods of low traffic to minimize potential disruptions.
</Message>

## Verifying workloads on the new pool

1. [**Cordon**](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_cordon/) the ENT1 nodes to prevent them from accepting new pods:
   ```
   kubectl cordon <your-ent1-node-name>
   ```

2. Drain the ENT1 nodes to reschedule workloads onto the POP2 nodes:
   ```
   kubectl drain <your-ent1-node-name> --ignore-daemonsets --delete-emptydir-data
   ```
   <Message type="note">
     The flags `--ignore-daemonsets` and `--delete-emptydir-data` may be necessary depending on your environment. Refer to the official [Kubernetes documentation](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#drain) for detailed information on these options.
   </Message>

These commands ensure that your workloads are running on the new POP2 nodes before proceeding to delete the ENT1 pool.

## Deleting the ENT1 pool

1. Return to your clusterâ€™s **Pools** tab and wait a few minutes to ensure all workloads have been rescheduled onto POP2 nodes.
2. Click the **three-dot menu** next to the ENT1 pool.
3. Select **Delete pool**.
4. Confirm the deletion.

## Verifying the migration

1. Run the following command to ensure no ENT1-based nodes remain:
   ```
   kubectl get nodes
   ```
   <Message type="note">
     Only **POP2** nodes should be listed.
   </Message>

2. Test your applications to confirm they are functioning correctly on the new POP2 nodes.

### Migration Highlights

- **Minimal disruption:** Kubernetes manages pod eviction and rescheduling automatically. However, the level of disruption may vary based on your specific workloads and setup. It is recommended to maintain multiple replicas of your services, set up [Pod Disruption Budgets (PDBs)](https://kubernetes.io/docs/tasks/run-application/configure-pdb/) to minimize downtime, and scale up workloads prior to the upgrade.
- **Flexible scaling:** You can configure the same autoscaling and autoheal policies on your POP2 pools as were set on your ENT1 pools.
- **Equivalent performance:** In most scenarios, POP2 Instances surpass the performance of ENT1 Instances, with additional CPU and memory-optimized variants available.

<Message type="tip">
  If you require assistance during the transitioning process, please [contact our Support team](https://console.scaleway.com/support/tickets).
</Message>