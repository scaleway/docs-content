---
meta:
  title: How to create and manage a GPU Instance
  description: This page explains how to create and manage a GPU Instance
content:
  h1: How to create and manage a GPU Instance
  paragraph: This page explains how to create and manage a GPU Instance
dates:
  validation: 2022-03-31
  posted: 2022-03-25
---

Scaleway GPU Instances are virtual compute instances equipped with dedicated high-end Nvidia graphical processing unit (GPUs). They are ideal for data processing, artificial intelligence, rendering and video encoding. After you have created your GPU Instance, you can [connect to it via SSH](/compute/instances/how-to/connect-to-instance) and run one of our ready-made [Docker images](/compute/gpu/how-to/use-gpu-with-docker) to access a [preinstalled environment](/compute/gpu/how-to/use-preinstalled-env) environment with all your [favorite AI libraries and tools](/compute/gpu/reference-content/docker-images/) already installed. In addition to this, GPU Instances have all the features of our regular Instances, including [flexible IPs](/compute/instances/how-to/use-flexips/), [Security Groups](/compute/instances/how-to/use-security-groups/), [Private Networks](/compute/instances/how-to/use-private-networks/), [backups](/compute/instances/how-to/create-a-backup/) and more. When you are done using your GPU Instance, you can easily [delete it](/compute/instances/how-to/delete-instance/) from the Scaleway console.

<Message type="requirement">

  - You have an account and are logged into the [Scaleway Console](https://console.scaleway.com)
  - You have [created your SSH Key and added it to your account](/console/my-project/how-to/create-ssh-key/)

</Message>

## How to create a GPU Instance

1. Click **Instances** in the **Compute** section of the side menu. The Instance creation page displays.

2. Click **Create an Instance**. The Instance creation wizard displays.

3. Complete the following steps in the wizard: 

    - Choose an **Availability Zone**, which is the geographical region where your GPU Instance will be deployed. GPU Instances are curently available in PAR-1 and/or PAR-2, depending on the GPU Instance type.
    - Select **GPU** as the **Instance type**, and then choose the type of GPU Instance you want. Different types have different prices, processing power, memory, storage options and bandwidth. 
    - Choose an **Image** to run on your GPU Instance. The following images are available:
      - **Ubuntu Focal GPU OS11**: our latest GPU OS image, with preinstalled Nvidia drivers and an Nvidia Docker environment. Other software is not pre-installed, as you are expected to use Docker to launch a working environment suitable for your needs. You can build your own container, use an official Docker image, or choose from our range of [Scaleway Docker images](/compute/gpu/reference-content/docker-images/), each of which has CUDA installed and is customised for different purposes.
      - **Ubuntu Bionic ML 10.1**: a legacy GPU OS image, with preinstalled Nvidia drivers, CUDA 10.1, an Nvidia Docker environment and a ready-to-use "ai" conda environment (preinstalled libraries include Numpy, pandas, scikit-learn, Tensorflow, Pytorch, Jax and Rapids).
      - **Ubuntu Bionic ML 9.2**: a legacy GPU OS image, with preinstalled Nvidia drivers, CUDA 9.2, an Nvidia docker environment and a ready-to-use "ai" conda environment (preinstalled libraries include Numpy, pandas, scikit-learn and Pytorch).
    - Add **Volumes**. This is an optional step. Volumes are storage spaces used by your Instances. You can leave the default settings of a minimum local storage, or choose to add more [Block](/compute/instances/concepts#block-volumes) and/or reduce [Local](/compute/instances/concepts#local-volumes) Storage to your GPU Instance. You can also choose which volume to run the OS from.
    - Enter a **Name** for your GPU Instance, or leave the randomly generated name in place. Optionally, you can also add [tags](/compute/instances/concepts#tags) to help you organize your GPU Instance. 
    - Click **Advanced Options** if you want to configure a [flexible IP](/compute/instances/concepts#flexible-ip), a local bootscript or a [cloud-init configuration](/compute/instances/concepts#cloud-init). Otherwise, leave these options at their default values. 
    - Verify the [SSH Keys](/console/my-account/concepts#ssh-key) that will give you access to your GPU Instance 
    - Verify the **Estimated Cost** of your GPU Instance, based on the specifications you chose.

4. Click **Create a new Instance** to finish. The creation of your GPU Instance begins, and you are informed when the GPU Instance is ready.

## How to connect to a GPU Instance

See our documentation on [how to connect to your Instance via SSH](/compute/instances/how-to/connect-to-instance/).

Once you have connected via SSH, you can [launch a Docker container](/compute/gpu/how-to/use-gpu-with-docker/) to start working on your AI projects.

## How to use Instance features

For instructions on using any type of GPU Instance feature, including flexible IPs, placement groups, Private Networks, backups, and much more, check out our full [Instance how-to documentation](/compute/instances/how-to/).

## How to delete a GPU Instance

See our documentation on [how to delete your Instance](/compute/instances/how-to/delete-instance/).

<Navigation title="See Also">
  <NextButton to="/compute/gpu/how-to/use-gpu-with-docker/">How to use Docker on your GPU Instance</NextButton>
</Navigation>
