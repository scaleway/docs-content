---
meta:
  title: How to create a Distributed Data Lab
  description: Step-by-step guide to creating a Distributed Data Lab on Scaleway.
content:
  h1: How to create a Distributed Data Lab
  paragraph: Step-by-step guide to creating a Distributed Data Lab on Scaleway.
tags: distributed data lab apache spark create process
dates:
  validation: 2024-07-15
  posted: 2019-05-11
categories:
  - managed-services
  - data-lab
---

Distributed Data Lab is a product designed to assist data scientists and data engineers in performing calculations on a remotely managed Apache Spark infrastructure.

<Macro id="requirements" />

- A Scaleway account logged into the [console](https://console.scaleway.com)
- [Owner](/identity-and-access-management/iam/concepts/#owner) status or [IAM permissions](/identity-and-access-management/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- [signed up to the private beta](https://www.scaleway.com/fr/betas/#distributed-data-lab) and received a confirmation email.
- An [Object Storage bucket](/storage/object/how-to/create-a-bucket/)
- A valid [API key](/identity-and-access-management/iam/how-to/create-api-keys/)

1. Click **Data Lab** under **Managed Services** on the side menu. The Distributed Data Lab page displays.

2. Click **Create Data Lab cluster**. The creation wizard displays.

3. Complete the following steps in the wizard:
    - Choose an Apache Spark version from the drop-down menu.
    - Set up your worker nodes by selecting a configuration, and by indicating a number of Apache Spark nodes.
    - Choose an Object Storage bucket in the desired region to store the configuration files, the output and the dependencies.
    - Enter a name for your Data Lab.
    - Optionnaly, add a description and/or tags for your Data Lab.
    - Verify the estimated cost.

4. Click **Create Data Lab cluster** to finish. You are directed to the Data Lab cluster overview page.


5. From the Data Lab cluster overview page, click **Open Notebook** in the **Notebook** section. You are directed to the notbook login page.

6. Enter your [API secret key](/identity-and-access-management/iam/concepts/#api-key) when prompted for a password, then click **Log in**. You are directed to the lab's home screen.

7. In the files list on the left, double-click the `quickstart.ipynb` file to open it.

8. Update the first cell of the file with your API access key and secret key, as shown below:

    ```json
    "spark.hadoop.fs.s3a.access.key": "[your-api-access-key]",
    "spark.hadoop.fs.s3a.secret.key": "[your-api-secret-key]",
    ```

