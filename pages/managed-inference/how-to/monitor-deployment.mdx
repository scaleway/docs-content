---
title: How to monitor a Managed Inference deployment
description: This page explains how to monitor a Managed Inference deployment
tags: managed-inference ai-data monitoring
dates:
  validation: 2025-09-22
  posted: 2024-03-06
---
import Requirements from '@macros/iam/requirements.mdx'


This documentation page shows you how to monitor your Managed Inference deployment with [Cockpit](/cockpit/quickstart/).

<Requirements />

  - A Scaleway account logged into the [console](https://account.scaleway.com/?service=elements)
  - A [Managed Inference deployment](/managed-inference/quickstart/)
  - [Owner](/iam/concepts/#owner) status or [IAM permissions](/iam/concepts/#permission) allowing you to perform actions in the intended Organization

## How to monitor your LLM dashboard

1. Click **Managed Inference** in the **AI** section of the [Scaleway console](https://account.scaleway.com/?service=elements) side menu. A list of your deployments displays.
2. From the drop-down menu, select the geographical region you want to manage.
3. Click a deployment name or <Icon name="more" /> > **More info** to access the deployment dashboard.
4. Click the **Monitoring** tab of your deployment. The Cockpit overview displays.
5. Click **Open Grafana metrics dashboard** to open your Cockpit's Grafana interface.
6. Authenticate with your [Grafana credentials](/cockpit/how-to/retrieve-grafana-credentials/). The Grafana dashboard displays.
7. Select your Managed Inference dashboard from the [list of your preconfigured dashboards](/cockpit/how-to/access-grafana-and-managed-dashboards/) to visualize your metrics.