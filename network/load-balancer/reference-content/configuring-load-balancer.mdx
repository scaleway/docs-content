---
meta:
  title: Configuring your Load Balancer
  description: Learn how to choose different settings and configurations for your Load Balancer depending on your needs
content:
  h1: Configuring your Load Balancer
  paragraph: Learn how to choose different settings and configurations for your Load Balancer depending on your needs
tags: load-balancer
categories: 
  - load-balancer
  - network
---

## Load Balancer Overview

Load Balancers allow you to distribute traffic and workload across multiple backend servers. They make it easy to scale your applications while ensuring continuous availability even in the event of heavy traffic. Each Load Balancer that you create is a highly available and fully managed Instance, consisting of one or more frontends and one or more backends. You can configure your Load Balancer according to your needs.

<Lightbox src="scaleway-load-balancer.webp" alt="" />

In this document, we explain some of the different configurations available when setting up your Load Balancer, and give examples of how to configure its frontends and backends for different use cases.

## Configuring a frontend

The frontend listens on the port you specify, and forwards received requests to the backend(s)

When creating a frontend, aside from the name the only configurable setting is that of the **port** it listens on.

### Choosing a port

For HTTP, a frontend will typically listen on port 80, while for HTTPS it will typically listen on port 443. 

After creating your Load Balancer, you can create multiple frontends to listen on different ports, and connect them to different backends as required. You can also set up custom [ACL rules](/network/load-balancer/how-to/create-manage-acls/) for each frontend.

## Configuring a backend 

The configuration that you choose for your Load Balancer's backend determines the manner in which it transfers requests to its associated backend servers.

A number of configuration settings are available.

<Message type="note">

  Here, the term "backend" refers to a set of configurations and target backend servers that determine how the Load Balancer forwards traffic. You can create one or more backends for your Load Balancer. The term "backend server" designates the target backend servers which the Load Balancer forwards traffic on to. Each backend must specify one or more backend servers (via their IP addresses) to forward to. All backend servers in a given backend should be able to serve the same requests in the same way.

</Message>

### Choosing a protocol and port 

The Load Balancer initiates connections to its backend servers using the protocol and port you define. 

* **HTTP protocol (typically port 80)**: The Load Balancer will initiate an HTTP connection with the backend server. Traffic will be forwarded without encryption.
* **HTTPS protocol (typically port 443)**: The Load Balancer will attempt to initiate an HTTPS connection with the backend server. In this case, the backend server must have an SSL/TLS certificate. Traffic will be forwarded using HTTPS, i.e. with encryption.
* **TCP protocol**: The Load Balancer will attempt to initiate a TCP (layer 4) connection to the backend server. 

### Choosing a Verify Certificate setting

If you select the HTTPS protocol, you are prompted to choose a Verify Certificate setting. Note that this setting does not display if you selected HTTP or TCP protocol.

When the Load Balancer initiates an HTTPS connection to a backend server, the backend server presents its certificate. 
- When Verify Certificate is selected, the Load Balancer checks the backend server's certificate and only connects if it is valid.
- When Verify Certificate is unselected, the Load Balancer does not check the backend server's certificate, connecting to the backend server regardless of the certificate's validity. 

This setting mostly concerns those using self-signed certificates on the backend server/s.

Note that the same Verify Certificate setting you select here will also be used for health checks, if you choose HTTPS for your [health check method](#choosing-a-health-check-method).

### Choosing a proxy protocol

Proxy protocol enables the original client IP address to be passed to the backend server in a standardized way. However, in order to work, the backend server must support the selected proxy protocol. 

* **No proxy protocol**:  Disable proxy protocol.
* **Proxy protocol v1**: Version one (text format).
* **Proxy protocol v2**: Version two (binary format).
* **Proxy protocol v2-ssl**: Version two with SSL information extension added, which provides information on SSL connection settings originally sent by the client.
* **Proxy protocol v2-ssl-cn**:  Version two with SSL information extension added as above, as well as the common name  from the sbject of the client certificate (if any).

### Choosing a health check method

Load Balancers should only forward traffic to “healthy” backend servers. To monitor the health of a backend server, health checks regularly attempt to connect to backend servers using the defined protocol to ensure that servers are up and listening. Various protocols for health checks are available:

* **HTTP**: When selecting HTTP heath checks, you are prompted to choose a **method** (`GET`, `POST` or `PUT`), the **URI** to be targeted, and the response **code** that signals a successful health check.
* **HTTPS**: The same method and fields as for an HTTP health check apply, but data transmission is encrypted. If you chose HTTPS as the main protocol for the Load Balancer's backend, the Verify Certificate setting you chose there is inherited for health checks. If you chose a different protocol for the Load Balancer's backend, the backend server's certificate will **not** be verified during health checks. See the [dedicated Verify Certificate section](#choosing-a-verify-certificate-setting) for more information.
* **MYSQL**: For MYSQL health checks, you are prompted to select the database username. Read more about this health check behavior [here](http://docs.haproxy.org/2.6/configuration.html#4.2-option%20mysql-check).
* **PGSQL**: For PGSQL health checks, you are prompted to select the database username. Read more about this health check behavior [here](http://docs.haproxy.org/2.6/configuration.html#4.2-option%20pgsql-check%20user).
* **LDAP**: No additional settings are required fr LDAP health checks. Read more about this health check behavior [here](http://docs.haproxy.org/2.6/configuration.html#4.2-option%20ldap-check).
* **Redis**: No additional settings are required for REDIS health checks. Read more about this health check behavior [here](http://docs.haproxy.org/2.6/configuration.html#4.2-option%20redis-check).
* **TCP**: No additional settings are required for TCP health checks. This check consists of a connection attempt that either fails or succeeds. Read more about this health check behavior [here](http://docs.haproxy.org/2.6/configuration.html#4.2-option%20tcp-check).

### Adding server IPs (backend servers)

You can add one or more IP addresses, either IPv4 or IPv6, of the backend servers your Load Balancer's backend will forward traffic to.

### Using advanced settings

Here, you have the option to activate **sticky sessions**. When activated, this bind a user's session to a specific server in the pool of backend servers. This ensures that all subsequent sessions from the user are sent to the same backend server while there is at least one active session. Sticky sessions can be **cookie based** or **table based**.

- **Cookie-based** stickiness uses an HTTP cookie to identify a session, and the server in the backend pool that it will stick to. For each incoming request without a stickiness cookie, the Load Balancer creates a cookie and selects a backend for the session. Subsequent requests providing this cookie will land on the same backend. You can customize the name of the cookie.
- **Table-based** stickiness uses the source (client) IP address to stick sessions to backends.

By default, when activating sticky sessions through the console, the cookie-based method is used when HTTP protocol is selected, and the table-based method is used when TCP protocol is selected. Use the [API](https://developers.scaleway.com/en/products/lb/zoned_api/) if you want to select table-based stickiness with HTTP protocol.

## Configuring a Load Balancer for SSL bridging

SSL bridging allows the user to initiate a secure HTTPS connection with the Load Balancer thanks to the Load Balancer frontend's SSL certificate. The Load Balancer decrypts incoming HTTPS traffic. This allows the Load Balancer to carry out layer 7 actions on the received traffic. The Load Balancer's backend then initiates a new HTTPS connection to re-encrypt traffic between the Load Balancer and the backend server, this time using the backend server's certificate. 

    <Lightbox src="scaleway-ssl-bridging.webp" alt="" />

To configure your Load Balancer for SSL bridging:

- The frontend must have a [certificate](/network/load-balancer/how-to/add-certificate).
- The frontend must be linked to a backend which uses HTTPS protocol.
- The backend server should have its own [certificate](/network/load-balancer/concepts#certificate).

## Configuring a Load Balancer for SSL offloading

SSL offloading, also known as SSL termination, allows the user to initiate a secure HTTPS connection with the Load Balancer thanks to the Load Balancer frontend's SSL certificate. The Load Balancer decrypts incoming HTTPS traffic. Layer 7 actions may therefore be applied to the traffic at this stage. Traffic is not re-encrypted on its way from the Load Balancer to the backend server, unlike with SSL bridging. Traffic that has gone through the offloading process is marked with a new header, called `X-Forwarded-Proto`, which informs the backend server that the client used HTTPS to contact the Load Balancer.

    <Lightbox src="scaleway-ssl-offloading.webp" alt="" />

To configure your Load Balancer for SSL offloading:

- The frontend must have a [certificate](/network/load-balancer/how-to/add-certificate).
- The frontend must be linked to a backend which uses HTTP protocol.
- The backend server does not need its own certificate.

## Configuring a Load Balancer for SSL passthrough

Passthrough is the simplest way to handle HTTPS traffic on a Load Balancer. As the name suggests, traffic is simply passed through the Load Balancer without being decrypted on it. Whilst this option generates very low overhead, no layer 7 actions can be carried out. This means that no cookie-based sticky sessions are possible with this method. In addition, if an application does not share sessions between servers, users’ sessions may get lost by being redirected to different servers of the group. 

    <Lightbox src="scaleway-ssl-passthrough.webp" alt="" />

To configure your Load Balancer for SSL passthrough:

- The frontend does not need a certificate and can listen on any port.
- The frontend must be linked to a backend which uses TCP protocol.
- The backend server must listen with its HTTP server process on the same port as configured for the backend.
- The backend server must have its own [certificate](/network/load-balancer/concepts#certificate).