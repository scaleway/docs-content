---
meta:
  title: Load Balancers - Concepts
  description: This page explains all the concepts related to Load Balancer
content:
  h1: Concepts
  paragraph: This page explains all the concepts related to Load Balancer
tags: advanced settings
categories:
  - networks
---

<Concept opened>

## Backends

Each Load Balancer is configured with one or several backends. A backend is a set of servers which receives forwarded requests from the frontend. You can [add and manage backends via the console](/network/load-balancer/how-to/manage-frontends-and-backends/).

</Concept>

<Concept opened>

## Frontends

Each Load Balancer is configured with one or several frontends. Frontends listen on a configured port, and forward requests to one or several backends. You can [add and manage frontends via the console](/network/load-balancer/how-to/manage-frontends-and-backends/).

</Concept>

<Concept opened>

## Health checks

Load Balancers should only forward traffic to “healthy” backend servers. To monitor the health of a backend server, health checks regularly attempt to connect to backend servers using the protocol and port defined by the forwarding rules to ensure that servers are listening. Various protocols for health checks are available, including HTTP, HTTPS, MYSQL, and more.

</Concept>

<Concept opened>

## High availability

A high availability (HA) setup is an infrastructure without a single point of failure. It prevents a server failure by adding redundancy to every layer of your architecture.

</Concept>

<Concept>


## Highly available IP address

This is an IP address, which is, by default, routed to the primary Load Balancer instance. In the event of a primary instance failure this address is automatically re-routed to the replica one. The highly available IP address is automatically created by default, when a Load Balancer is created. It can also be conserved when a Load Balancer is deleted and re-used later.

</Concept>

<Concept>

## Load Balancers
[Load Balancers](/network/load-balancer/how-to/create-load-balancer/) are highly available and fully managed instances that allow you to distribute workload across multiple servers. They ensure the scaling of all your applications while securing their continuous availability, even in the event of heavy traffic. They are commonly used to improve the performance and reliability of web sites, applications, databases and other services.

</Concept>

<Concept>

## Protocol

A protocol is a standard format for communication over a network. When you configure your Load Balancer's backend, you choose a protocol (HTTP, HTTPs or TCP) which it uses to send and receive data.

</Concept>

<Concept>

## Proxy protocol

Proxy protocol is an internet protocol used to transfer connection information from the client (eg the client's IP address), through the Load Balancer and on to the destination server.

</Concept>

<Concept>

## SSL bridging

[SSL bridging](/network/load-balancer/how-to/setup-ssl-offloading#how-to-#how-to-configure-tlsssl-bridging) removes SSL-based encryption from HTTPS traffic coming into the Load Balancer (as with SSL offloading), but then initiates a new SSL connection to rencrypt traffic between the Load Balancer and the backend servers.

</Concept>

<Concept>

## SSL offloading

[SSL offloading](/network/load-balancer/how-to/setup-ssl-offloading#how-to-configure-tlsssl-offloading) removes SSL-based encryption from HTTPS traffic coming into the Load Balancer.

</Concept>

<Concept>

## SSL passthrough

[SSL passthrough](/network/load-balancer/how-to/setup-ssl-offloading#how-to-configure-tlsssl-passthrough) is the simplest way to handle HTTPS traffic on a Load Balancer. As the name suggests, traffic is simply passed through the Load Balancer without being decrypted.

</Concept>

<Concept>

## Sticky session

A sticky session enables the Load Balancer to bind a user’s session to a specific Instance. This ensures that all subsequent sessions from the user are sent to the same Instance, while there is at least one active session.

</Concept>
