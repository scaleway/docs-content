---
meta:
  title: Serverless Containers FAQ
  description: Discover Serverless Containers and Serverless architecture.
content:
  h1: Serverless Containers FAQ
dates:
  validation: 2025-04-02
category: serverless
productIcon: ContainersProductIcon
---

## Overview

### What is serverless computing, and how does it differ from traditional cloud hosting?

Serverless computing is a cloud execution model where the cloud provider dynamically manages the allocation of compute resources. Unlike traditional hosting models, you do not need to provision, scale, or maintain servers. Instead, you focus solely on writing and deploying your code, and the infrastructure scales automatically to meet demand.

### Why consider using Serverless Containers, Functions, or Jobs for my projects?

These services allow you to build highly scalable, event-driven, and pay-as-you-go solutions. Serverless Containers and Functions help you create applications and microservices without worrying about server management, while Serverless Jobs lets you run large-scale, parallel batch-processing tasks efficiently. This can lead to faster development cycles, reduced operational overhead, and cost savings.

Refer to the [dedicated documentation](/serverless-containers/reference-content/difference-jobs-functions-containers/) for more information on the differences between Containers, Functions and Jobs.

### Can I run any application on Serverless Containers?

Yes. Because Serverless Containers supports any containerized application, you can choose the language, runtime, and framework that best suits your needs. As long as it can run in a container and respond to HTTP requests, Serverless Containers can host it.

### What are the cost benefits of using serverless services like Serverless Containers?

With serverless, you only pay for the computing resources you use. There are no upfront provisioning costs or paying for idle capacity. When your application traffic is low, the cost scales down, and when traffic spikes, the platform automatically scales up, ensuring you never overpay for unused resources.

### Are applications deployed on Serverless Containers stateless?

Yes, all applications deployed on Serverless Containers are stateless. This means the server does not store any state about the client session. Instead, the session data is stored on the client and passed to the server as needed.


## Billing

### How am I billed for Serverless Containers?

#### Principles

Serverless Containers are billed on a pay-as-you-go basis, strictly on resource consumption (Memory and CPU).

* **Memory consumption:** The memory consumption is obtained by multiplying the memory tier chosen by the container run duration.
* **vCPU consumption:** The vCPU consumption is obtained by multiplying the vCPU tier chosen by the container run duration.
* **Ephemeral storage:** Is free of charge, the maximum value of ephemeral storage depends on the memory value.

<Lightbox src={["scaleway-caas-billing-1.webp", "scaleway-caas-billing-2.webp"]} size={"medium"}  alt={["Serverless Containers Billing", "Serverless Containers Billing"]} />

#### Prices

* **Memory consumption:** €0.10 per 100 000 GB-s, and we provide a **400 000 GB-s free tier** per account and per month.

    | Memory   | Price per second  |
    |--------- |------------------ |
    | 128 MB   | €0.000000125 	   |
    | 256 MB   | €0.00000025  	   |
    | 512 MB   | €0.0000005   	   |
    | 1024 MB  | €0.000001 	       |
    | 2048 MB  | €0.000002    	   |
    | 3072 MB  | €0.000003    	   |
    | 4096 MB  | €0.000004    	   |

* **vCPU consumption:** €1.00 per 100 000 vCPU-s, and we provide a **200 000 vCPU-s free tier** per account per month.

    | CPU       	| Price per second  |
    |------------ |------------------ |
    | 0.07 vCPU 	| €0.0000007 	      |
    | 0.14 vCPU 	| €0.0000014	      |
    | 0.28 vCPU 	| €0.0000028        |
    | 0.56 vCPU 	| €0.0000056	      |
    | 1.12 vCPU 	| €0.0000112        |

#### Example

| Criteria                   | Value        	|
|--------------------------- |--------------	|
| Monthly duration           | 30 000 000 s 	|
| Amount of memory allocated | 128 MB       	|
| Amount of vCPU allocated   | 70 mvCPU     	|
| Free tier                  | Yes          	|

##### Price calculation

* **Memory consumption**
    * *Allocated Memory conversion:* 128 MB = 0.125 GB
    * *Resource consumption:* 30 000 000 s * 0.125 GB = 3 750 000 GB-s
    * *Free tier:* 400 000 GB-s
    * *Billed resources:* 3 750 000 - 400 000 = 3 350 000 GB-s
    * *Cost:* 3 350 000 * €0.0000010 = **€3.35**
* **vCPU consumption**
    * *Allocated vCPU conversion:* 70mvCPU = 0.070 vCPU
    * *Resource consumption:* 30 000 000 s * 0.070 vCPU = 2 100 000 vCPU-s
    * *Free tier:* 200 000 vCPU-s
    * *Billed resources:* 2 100 000 - 200 000 = 1 900 000 vCPU-s
    * *Cost:* 1 900 000 * €0.0000100 = **€19.00**

**Monthly Cost: €22.35**

## Resources and performance

### Can I upgrade Serverless Container resources (vCPU and RAM) at any time?

Yes, Serverless Containers resources can be changed at any time without causing downtime.

### How does scaling work in these serverless services?

Scaling in Serverless Containers and Serverless Functions is handled automatically by the platform. When demand increases - more requests or events - the platform spins up additional instances to handle the load. When demand decreases, instances spin down. This ensures optimal performance without manual intervention.

### Can updates of Serverless Containers cause downtime?

No, deploying a new version of your Serverless Container generates a **rolling update**. This means that a new version of the service is gradually rolled out to your users without downtime. Here is how it works:

* When a new version of your container is deployed, the platform automatically starts routing traffic to the new version incrementally, while still serving requests from the old version until the new one is fully deployed.
* Once the new version is successfully running, we gradually shift all traffic to it, ensuring zero downtime.
* The old version is decommissioned once the new version is fully serving traffic.

This process ensures a seamless update experience, minimizing user disruption during deployments. If needed, you can also manage traffic splitting between versions during the update process, allowing you to test new versions with a subset of traffic before fully migrating to it.

### Can I migrate existing applications to Serverless Containers?

Yes. Many traditional applications can be containerized and deployed to Serverless Containers. This makes it easier to modernize legacy systems without a complete rewrite. By moving to a serverless platform, you gain automatic scaling, reduced operational overhead, and a simpler infrastructure management experience.

### How can I select the right resources (vCPU/RAM/ephemeral storage) for Serverless Containers ?

Insufficient vCPU, RAM or ephemeral storage can lead to containers going to error status. Make sure to provision enough resources for your container.

We recommend you set high values, [use metrics to monitor](/serverless-containers/how-to/monitor-container/) the resource usage of your container, then adjust the values accordingly.

### How can I reduce the cold-starts of Serverless Containers ?

* **Optimize the startup**: Cold-starts can be affected by loading a large number of dependencies and opening several resources at startup.
Ensure that your code avoids heavy computations or long-running initialization at startup and optimize the number of loaded libraries.

* **Keep your container warm**: You can use CRON triggers at certain intervals to keep your container warm or set the min-scale parameter to `1` when required.

* **Increase resources**: Adding more vCPU and RAM can help to significantly reduce the cold-starts of your container.

* **Use sandbox v2**: We recommend you use sandbox v2 (advanced settings) to reduce cold starts.

* **Reduce image size**: Ensure your image is small and clean. [Read our tips for keeping image sizes down](/serverless-containers/reference-content/containers-limitations/#image-size).

### Which Linux syscalls are supported?

- [Sandbox](/serverless-containers/concepts/#sandbox) v1 guarantees full compatibility with Linux syscalls.

- [Sandbox](/serverless-containers/concepts/#sandbox) v2 relies on [gVisor](https://gvisor.dev/), which implements a selection of syscalls. Refer to the [official gVisor documentation](https://gvisor.dev/docs/user_guide/compatibility/linux/amd64/) for a comprehensive list of supported syscalls.

### What are the limitations of Serverless Containers?

Refer to our dedicated page about [Serverless Containers limitations and configuration restrictions](/serverless-containers/reference-content/containers-limitations/) for more information.

### Why does my container have an instance running after deployment, even with min-scale 0?

Currently, a new container instance will always start after each deployment, even if there is no traffic and the minimum
scale is set to 0. This behavior is not configurable at this time.

## Usage

### How can I deploy my containers?

There are several ways to deploy containers. Refer to the [dedicated documentation](/serverless-containers/reference-content/deploy-container/) to determine the best method for your use case.

### How do I integrate my serverless solutions with other Scaleway services?

Integration is straightforward. Serverless Functions and Containers can be triggered by events from [Queues](/queues/concepts/#scaleway-queues) and [Topics and Events](/topics-and-events/concepts/#topics-and-events), and can easily communicate with services like [Managed Databases](/managed-databases-for-postgresql-and-mysql/) or [Serverless databases](/serverless-sql-databases/). [Serverless Jobs](/serverless-jobs/) can pull data from [Object Storage](/object-storage/), or output processed results into a database. With managed connectors, APIs, and built-in integrations, linking to the broader Scaleway ecosystem is seamless.

### Where should I host my container images for deployment ?

<Macro id="container-registry-note" />

### How can I copy an image from an external registry to Scaleway Container Registry?

You can copy an image from an external registry using the Docker CLI, or open source third-party tools such as [Skopeo](https://github.com/containers/skopeo). Refer to the [dedicated documentation](/serverless-containers/api-cli/migrate-external-image-to-scaleway-registry/) for more information.

### How do Serverless Containers namespaces and Container Registry namespaces interact?

Serverless Containers namespaces and Container Registry namespaces observe the following behaviors:

- Creating a Serverless Containers namespace implicitly creates an empty Container Registry namespace.

- Creating a Container Registry namespace **does not** create a Serverless Containers namespace.

- Serverless Containers and Container Registry namespace are not linked.

- With Serverless Containers, you can use images from any Container Registry namespace, as long as they are in the same [Project](/organizations-and-projects/concepts/#project).

- If you delete the Container Registry namespace associated with a Serverless Containers namespace, it will be created again when deploying a container within this Serverless Containers namespace.

 ### How can I call my containers periodically?

 Scaleway Serverless Containers natively support CRON triggers to call your containers periodically. This feature has many applications, such as scheduled data processing, maintenance tasks, monitoring, or reporting.
 
 Periodic CRON triggers also allow you to maintain your containers active during specific time slots to reduce cold start latency, without having to provision a minimum of 1 vCPU at all times.

 Refer to the [dedicated documentation](/serverless-containers/how-to/add-trigger-to-a-container/) for more information on how to create CRON triggers for your containers.

 To learn more about how CRONs work, refer to our [CRON schedule reference documentation](/serverless-containers/reference-content/cron-schedules/).

### How do Serverless Containers health checks work ?

A Serverless Container is set to `ready` once the specified port is correctly bound to the container, and will start receiving traffic. If your application needs to perform some tasks before receiving traffic (e.g. connect to a database), it is important to run them before binding to the port (starting the webserver).
For now, the `HEALTHCHECK` Docker directive has no impact on container readiness. In the future, the health check will be customizable for your applications.

### How do I know if my application is compatible with Serverless Containers ?

Your application is compatible with Serverless Containers if it meets the following criteria:

- It must handle requests delivered via HTTP, HTTP/2, WebSockets, or gRPC.
- It must not require persistent local storage due to [ephemeral storage](/serverless-containers/concepts/#ephemeral-storage), and must use shared file storage systems like [Object Storage](https://www.scaleway.com/en/docs/object-storage/)
- It must fit the [Serverless Containers limitations](/serverless-containers/reference-content/containers-limitations/)
- It must expose a webserver port and be listening on `0.0.0.0`.

## Network and storage

### Can I redirect all HTTP traffic to HTTPS?

Yes, you can [redirect all inbound HTTP connections to HTTPS](/serverless-containers/how-to/manage-a-container/#manage-a-deployment-from-the-scaleway-container-registry) by enabling **HTTPS connections only** in the **Security** tab of the **Advanced options** of your container.

### Can I whitelist the IPs of my containers?

Serverless Containers does not yet support Private Networks. However, you can use the Scaleway IP ranges defined at [https://www.scaleway.com/en/peering/](https://www.scaleway.com/en/peering/) on Managed Databases and other products that allow IP filtering.

### Which protocols are supported by Serverless Containers?

Serverless Containers support **http1** and **http2**. **http1** is enabled by default, but some services (e.g., gRPC) only support **http2**.

You can [modify the protocol](/serverless-containers/how-to/manage-a-container/#manage-a-deployment-from-the-scaleway-container-registry) used by your container from the **Requests tab** of the **Advanced options**.

### Why does my gRPC container not respond?

Containers use **http1** by default, yet the gRPC protocol requires `http2`. You can upgrade the protocol to `http2` (`h2c`).

### How can I configure access to a Private Network or Virtual Private Cloud (VPC)?

Scaleway Serverless Containers does not currently support Scaleway VPC or Private Networks, though this feature is under development.

To add network restrictions on your resource, refer to the [list of prefixes used at Scaleway](https://www.scaleway.com/en/peering/). Serverless resources do not have dedicated or predictable IP addresses.

### Can I use my own TLS certificates for custom domains?

No, you cannot use your own TLS certificates. Scaleway uses Let's Encrypt to generate and automatically renew certificates on your [Custom Domains](https://www.scaleway.com/en/docs/serverless-containers/concepts/#custom-domain)

### Can I connect to my container using SSH?

No, it is not possible to connect to Serverless Containers using SSH. Serverless Containers is a fully managed, and stateless compute environment that does not provide direct access to the underlying infrastructure due to several features, such as autoscaling.

For monitoring and debugging purposes, you can inspect your container, and interact with it using [Scaleway Cockpit](/serverless-containers/how-to/monitor-container/).

### How can I attach Block Storage to a Serverless Container?

Scaleway Serverless Containers do not currently support attaching Block Storage. These containers are designed to be
stateless, meaning they do not retain data between invocations. For persistent storage, we recommend using external solutions like Scaleway Object Storage.

### How can I store data in my Serverless resource?

Serverless resources are by default [stateless](/serverless-containers/concepts/#stateless), local storage is ephemeral.

For certain use cases, such as saving analysis results or exporting data, it can be important to have permanent storage to save data. Serverless resources can be connected to other resources from the Scaleway ecosystem for this purpose:

#### Databases

* [Serverless Databases](/serverless-sql-databases/): Go full serverless and take the complexity out of PostgreSQL database operations.
* [Managed MySQL / PostgreSQL](/managed-databases-for-postgresql-and-mysql/): Ensure scalability of your infrastructure and storage with our new generation of Managed Databases designed to scale on-demand according to your needs.
* [Managed Database for Redis®](/managed-databases-for-redis/): Fully managed Redis®* in seconds.
* [Managed MongoDB®](/managed-mongodb-databases/): Get the best of MongoDB® and Scaleway in one database.

#### Storage

* [Object Storage](/object-storage/): Multi-AZ resilient object storage service ensuring high availability for your data.
* [Scaleway Glacier](/object-storage/): Our outstanding Cold Storage class to secure long-term object storage. Ideal for deep archived data.

<Message type="tip">
Explore all Scaleway products in the console and select the right product for your use case.

Further integrations are also possible even if not listed above, for example, [Secret Manager](/secret-manager/) can help you to store information that requires versioning.
</Message>

### Can I use Serverless Containers with Edge Services?

You cannot use Serverless Containers with Edge Services because there are no native integrations between the two products yet.

### Can I use the IP address of a Serverless Function?

By design, it is not possible to guarantee static IPs on Serverless compute resources.
