---
meta:
  title: How to query text models
  description: Learn how to interact with powerful text models using Scaleway's Generative APIs service.
content:
  h1: How to query text models
  paragraph: Learn how to interact with powerful text models using Scaleway's Generative APIs service.
tags: generative-apis ai-data text-models
dates:
  validation: 2024-08-28
  posted: 2024-08-28
---

Scaleway's Generative APIs service allows users to interact with powerful text models hosted on the platform through the Chat API.
The Chat API is an OpenAI-compatible REST API for generating and manipulating conversations.

There are several ways to interact with text models
- The Scaleway [console](https://console.scaleway.com) provides a complete [playground](/ai-data/generative-apis/how-to/query-text-models/#accessing-the-playground), where you can test models, adapt parameters, and observe how these changes affect the output in real time.
- Via the [Chat API](/ai-data/generative-apis/how-to/query-text-models/#querying-text-models-via-api)

<Macro id="requirements" />

- A Scaleway account logged into the [console](https://console.scaleway.com)
- [Owner](/identity-and-access-management/iam/concepts/#owner) status or [IAM permissions](/identity-and-access-management/iam/concepts/#permission) allowing you to perform actions in the intended Organization
- A valid [API key](/identity-and-access-management/iam/how-to/create-api-keys/) (Necessary for API authentication)
- Python 3.7+ installed on your system.

## Accessing the Playground

The Playground within the Scaleway console offers an intuitive interface for experimenting with text models. To access it:

1. Click **Generative APIs** in the **AI** section of the side menu of the Scaleway console. The [list of available serverless models](https://console.scaleway.com/generative-apis/) displays.
2. Click <Icon name="more" /> next to the name of the model you want to use. Then click **Try model** in the pop-up menu. The **Playground chat** displays.
3. Enter your prompt in the form to start interacting with the model.

In the Playground, you can enter prompts, adjust model parameters, and immediately see the results of your queries. This is an excellent way to understand the models' capabilities and fine-tune your inputs for better results.

## Querying text models via API

While the Playground provides a hands-on environment for testing, you can also query the models programmatically using your favorite tools or languages.
In the following example, we will use the OpenAI Python client.

### Installing the OpenAI SDK

You can install it using pip:

```bash
pip install openai
```

### Initializing the client

Initialize the OpenAI client with your base URL and API key:

```python
from openai import OpenAI

# Initialize the client with your base URL and API key
client = OpenAI(
    base_url="https://api.scaleway.ai/v1",  # Scaleway's Generative APIs service URL
    api_key="<SCW_API_KEY>"  # Your unique API key from Scaleway
)
```

### Generating text with a chat completion

You can now create a chat completion, for example with the `llama-3.1-8b-instruct` model. Following you can find an example:

```python
# Create a chat completion using the 'llama-3.1-8b-instruct' model
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Describe a futuristic city with advanced technology and green energy solutions."}],
    temperature=0.7,  # Adjusts creativity
    max_tokens=100,   # Limits the length of the output
    top_p=0.9         # Controls diversity through nucleus sampling
)

# Print the generated response
print(response.choices[0].message["content"])
```

This code sends a message to the model and returns an answer based on your input. The `temperature`, `max_tokens`, and `top_p` parameters control the response's creativity, length, and diversity, respectively.

A conversation style may include a default system prompt. You may set this prompt by setting the first message with the role system. For example:

```python
[
  {
  	"role": "system",
  	"content": "You are Xavier Niel."
  },
  {
  	"role": "user",
  	"content": "Hello, what is your name?"
  }
]
```

### Model parameters and their effects

The following parameters can be adjusted to influence the output of the model:

- **`messages`**: A list of message objects that represent the conversation history. Each message should have a `role` (e.g., "system", "user", "assistant") and `content`.
- **`temperature`**: Controls the output's randomness. Lower values (e.g., 0.2) make the output more deterministic, while higher values (e.g., 0.8) make it more creative.
- **`max_tokens`**: The maximum number of tokens (words or parts of words) in the generated output.
- **`top_p`**: An alternative to `temperature`, controlling the diversity of the output. It uses nucleus sampling, where the model considers the tokens with top probabilities until the cumulative probability reaches `top_p`.
- **`n`**: The number of completions to generate for the prompt. This is useful for getting multiple variations of the response.
- **`stop`**: A string or list of strings where the model will stop generating further tokens. This is useful for controlling the end of the output.

<Message type="tip">
 You can experiment with these parameters in the Playground to see how they affect the modelâ€™s responses.
</Message>

## Advanced usage tips

### Using the Playground for testing

The Playground allows you to test and tweak your queries and fine-tune parameters interactively. This can help you identify the best settings for your application without writing any code.

For example, you can:

- Adjust the `temperature` slider to see how it affects the creativity of the model.
- Modify the `max_tokens` to see how the length of the response changes.
- Set specific `stop` sequences to control where the model stops its output.

<Message type="warning">
 If you encounter an error such as "Forbidden 403" refer to the [API documentation](/ai-data/generative-apis/api-cli/understanding-errors) for troubleshooting tips.
</Message>