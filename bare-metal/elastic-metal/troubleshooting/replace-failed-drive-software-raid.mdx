---
meta:
  title: Replacing a failed drive in a software RAID
  description: Replacing a failed drive in a software RAID
content:
  h1: Replacing a failed drive in a software RAID
  paragraph: Replacing a failed drive in a software RAID
tags: RAID elastic-metal failed-drive 
categories:
  - bare-metal
  - elastic-metal
dates:
  validation: 2023-12-22
  posted: 2022-08-26
---

Each Elastic Metal server uses a RAID1 configuration after installation from the Scaleway console. If you want to change the RAID configuration of the server, you can modify the RAID array using [rescue mode](/bare-metal/elastic-metal/how-to/use-rescue-mode/).

<Macro id="iam-requirements" />

## Removing the failed disk from the RAID configuration

<Message type="tip">
  We recommend backing up your data before proceeding.
</Message>

1. Boot server in [rescue mode](/bare-metal/elastic-metal/how-to/use-rescue-mode/) from the Scaleway console.
2. Log in to the server using the rescue account:
    ```
    ssh em-XXX@<your_elastic_metal_ip>
    ```

    <Message type="tip">
      The rescue credentials are available from your server's status page in the Scaleway console.
    </Message>
2. Run the following command to make sure all disk caches are written to the disk:
    ```
    sync
    ```
3. Mark the failed disk as failed using `mdadm`:
    ```
    mdadm --manage /dev/md0 --fail /dev/sdb2
    ```
4. Visualize the existing `mdadm` RAID devices by running the following command:
    ```
    cat /proc/mdstat
    ```

    An output as follows displays:

    ```sh
    Personalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10]
    md126 : active (auto-read-only) raid1 sdb3[1] sda3[0]
          974869504 blocks super 1.2 [2/2] [UU]
            resync=PENDING
          bitmap: 8/8 pages [32KB], 65536KB chunk

    md127 : active (auto-read-only) raid1 sdb2[1](F) sda2[0]
          523264 blocks super 1.2 [2/2] [UU]

    unused devices: <none>
    ```

    The faulty device is marked with `(F)`.
5. Remove the failed disk using the `mdadm --manage` command:
    ```sh
    root@elastic-metal:~# # mdadm --manage /dev/md0 --remove /dev/sdb2
    ```
6. Contact the technical support to replace the failed disk with a working one.

## Adding the replacement disk to the RAID

1. Once the failed disk is replaced, copy the partition table of the source disk to the new disk:
    ```
    sfdisk -d /dev/sda | sfdisk /dev/sdb
    ```

    <Message type="important">
      The `sfdisk` command above replaces the entire partition table on the new disk with the one of the source disk. Modify the command if you require preserving other partition information on the disk.
    </Message>
2. Create a mirror of the source disk using the `mdadm` command:
    ```
    mdadm --manage /dev/md0 --add /dev/sdb2
    ```
3. Verify the status of the configuration:
    ```
    mdadm --detail /dev/md0
    ```

    <Message type="tip">
    Use the following command to show the progress of the recovery of the mirror disk:
    ```
    cat /proc/mdstat
    ```

    </Message>