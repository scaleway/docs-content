---
meta:
  title: Serverless Jobs
  description: Discover Scaleway's Serverless Jobs
content:
  h1: Serverless Jobs
hero: assets/serverless-jobs.webp
---

<Concept>

## What are Serverless Jobs?

Scaleway Serverless Jobs is a fully managed service that enables efficient execution of batch computing workloads. It automates management tasks, allowing users to run large-scale batch jobs with ease.

</Concept>

<Concept>

## What types of workloads are best suited for Serverless Jobs?

Serverless Jobs is ideal for tasks such as data processing, analysis and various computational operations that can be executed in a non-interactive batch mode. You can execute short and long-running jobs.

</Concept>

<Concept>

## How can I monitor the activity of my Serverless Jobs?

Serverless Jobs are integrated with [Cockpit](/observability/cockpit/quickstart/), Scaleway's observability service. Cockpit allows you to see all the logs and metrics associated with your job runs](/serverless/jobs/concepts/#job-run). Additionnally, each job run has a status that provides you with real-time information on your job's execution.

</Concept>

<Concept>

## Can I cancel or modify a Serverless Job after it has started?

An ongoing Serverless Job can be interrupted during its execution from the **Job runs** section of a job's **Overview** tab.

</Concept>

<Concept>

## How can I automate the deployment and management of Scaleway Serverless Jobs?

Scaleway Serverless Jobs is part of the Scaleway ecosystem, it can therefore be driven using the [Scaleway CLI](/developer-tools/scaleway-cli/quickstart/), the [Scaleway API](https://www.scaleway.com/en/developers/api/), and other [developer tools](https://www.scaleway.com/en/developers/). Our serverless ecosystem offers a lot of possibilites with event-driven architectures, and integrations with more products of the Scaleway ecosystem are under active development.

</Concept>

<Concept>

## Do Serverless Jobs offer parallelization?

Not yet. Scaleway Serverless Jobs will soon offer parallelization via a `parallelism` parameter for each job. This will automatically launch a given number of replicas of the Job container in parallel.

</Concept>