---
title: Containers - Concepts
description: Key concepts of Scaleway Serverless Containers.
tags: containers cold-start concurrency container-registry environment-variables jwt vcpu serverless scale autoscaling
dates:
  validation: 2025-05-26
---
import ServerlessConcepts from '@macros/serverless/serverless-concepts.mdx'

## Autoscaling

Autoscaling refers to the ability of Serverless Containers to automatically adjust the number of instances without manual intervention.
Scaling mechanisms ensure that resources are provisioned dynamically to handle incoming requests efficiently while minimizing idle capacity and cost.

Autoscaling parameters are [min-scale](/serverless-containers/concepts/#min-scale) and [max-scale](/serverless-containers/concepts/#max-scale). Available scaling policies are:
* **Concurrent requests:** requests incoming to the resource at the same time. Default value suitable for most use cases.
* **CPU usage:** to scale based on CPU percentage, suitable for intensive CPU workloads.
* **RAM usage** to scale based on RAM percentage, suitable for memory-intensive workloads.

Refer to the [dedicated documentation](/serverless-containers/reference-content/containers-autoscaling/) for more information on autoscaling.

### Min scale

Customizing the minimum scale for Serverless can help ensure that an instance remains pre-allocated and ready to handle requests, reducing delays associated with [cold starts](#cold-start). However, this setting also impacts the costs of your Serverless Container.

For **CPU** and **RAM** based autoscaling, the `min-scale` value must be at least `1`.

### Max scale

This parameter sets the maximum number of container instances.

You should adjust it based on your container's traffic spikes, keeping in mind that you may wish to limit the maximum scale to manage costs effectively while provisioning enough containers to handle spikes.

### Scale to zero

When provisioned with a [minimum scale](#min-scale) of `0`, Serverless Containers scale down to zero active instances as long as they are not triggered. While idling, they do not consume any resources, which allows to reduce the cost of your infrastructure.

## Cold start

Cold start is the time a Container takes to handle a request when it is called for the first time.

The startup process steps are:
* Downloading the container image to our infrastructure
* Starting the container. Optimize your container startup speed to minimize this step (e.g., avoid waiting for slow connections or downloading large objects at startup)
* Waiting for the container to listen on the configured port.

[How to reduce cold starts](/serverless-containers/faq/#how-can-i-reduce-the-cold-starts-of-serverless-containers).

## Commands and arguments

Serverless Containers allows you to customize the `command` and `args` instructions of your container image directly from the [Scaleway console](https://console.scaleway.com) and via the [Scaleway API](https://www.scaleway.com/en/developers/api/serverless-containers/).

- The `command` instruction defines the command, process, or script executed when your container starts.
- The `args` instruction defines the arguments passed to the `command` instruction. Arguments can be passed as environment variables, as shown in the example below.

**Example**

```yaml
env:
- name: MESSAGE
  value: "hello world"
command: ["/bin/echo"]
args: ["$(MESSAGE)"]
```

Refer to the [official Kubernetes documentation](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/) for more information on commands and arguments behavior.

### Arguments

See [Commands and arguments](#commands-and-arguments).

## Concurrency

Concurrency defines the number of simultaneous requests a single instance of your container can handle at the same time. Once the number of incoming requests exceeds this value, your container scales according to your parameters.

Refer to the [dedicated documentation](/serverless-containers/reference-content/containers-concurrency/) for more information on container concurrency.

## Container

A container is a package of software that includes all dependencies: code, runtime, configuration, and system libraries so that it can run on any host system.

## Container image

A container image is a file that includes all the requirements and instructions of a complete and executable version of an application. Container images can be easily stored using [Scaleway Container Registry](/container-registry/quickstart/).

## Container Registry

Container Registry is the place where your images are stored before being deployed. We recommend using [Scaleway Container Registry](/container-registry/quickstart/) for optimal integration and performance. See the [migration guide](/serverless-containers/api-cli/migrate-external-image-to-scaleway-registry/) for full details.

## Deployment

Some parameter changes require a new deployment of the container to take effect. The deployment happens without causing downtime, as traffic is switched to the newest version once it is ready.

Refer to the [dedicated documentation](/serverless-containers/reference-content/deploy-container/) for information on the different deployment methods.

## Endpoint

An endpoint is the URL generated to access your resource. It can be customized with [custom domains](#custom-domain).

### Custom domain

By default, a generated endpoint is assigned to your Serverless resource. Custom domains allow you to use your own domain - see our [custom domain documentation](/serverless-containers/how-to/add-a-custom-domain-to-a-container) for full details.

## Environment variables

Environment variables are key/value pairs injected into your container. They are useful to share information such as configurations with your container. Environment variables defined at the container level override the ones defined at the namespace level if they have the same name.

Some names are reserved. [See details about reserved names](/serverless-containers/reference-content/containers-limitations/#configuration-restrictions).

## Ephemeral storage

In addition to vCPU and RAM, Serverless Containers also provide a storage volume for the duration of the task. This storage space allows you to hold data during the life of the Serverless Container instance and disappears once the execution is complete.

The maximum size of the ephemeral storage is tied to the allocated memory.

## Health check

To determine the status of a container, the default health check automatically checks if basic requirements are met, to define the status as `ready`. You can customize the following elements to better fit your use case:
- The **probe type** defines the type of check to perform to define if your container is ready:
    - The **TCP** probe will check if the TCP connection of your Serverless Container is opened on the specified port
    - The **HTTP** probe allows you to define a custom path to your Serverless Container to get the readiness status. It can be useful to check if all requirements are met, such as the connection to the database, etc.
- The **failure threshold** corresponds to the maximum number of checks that can fail before declaring the Serverless Container in error. Defaults to 30.
- The **interval** corresponds to the duration in seconds between every check. Defaults to 10 seconds.
- The **path** (HTTP probe type only) corresponds to the endpoint to call you Serverless Container (example: `/health`).

You can define custom health check rules via the [Scaleway console](/serverless-containers/how-to/manage-a-container/) or set a [specific endpoint via the Scaleway API](https://www.scaleway.com/en/developers/api/serverless-containers/#path-containers-create-a-new-container).

## Instance

A Serverless Container instance handles incoming requests based on factors like the request volume, min scale, and max scale parameters.

## Load balancing

The Serverless infrastructure manages incoming request traffic. In scenarios like sudden traffic spikes or load testing, resources are automatically scaled based on the max scale parameter to handle the load.

## Monitoring

Monitoring is the process of continuously collecting and analyzing data about your Serverless applications and infrastructure to ensure they are healthy, performing well, and available.

### Logging

Serverless Containers offers a built-in logging system based on Cockpit to track the activity of your resources. Refer to [monitoring Serverless Containers](/serverless-containers/how-to/monitor-container/) for more information.

### Metrics

Performance metrics for your Serverless resources are natively available. Refer to [monitoring Serverless Containers](/serverless-containers/how-to/monitor-container/) for more information.

## Namespace

A namespace is a folder with some settings that allows you to group your containers. Containers in the same namespace can share environment variables, secrets, and access tokens, defined at the namespace level.

Refer to the [dedicated documentation](/serverless-containers/how-to/create-manage-delete-containers-namespace/) for information on how to create, manage, and delete namespaces.

## Port

The port of a containerized application refers to the network port that the application inside the container listens on for incoming requests.

Refer to the [dedicated documentation](/serverless-containers/reference-content/port-parameter-variable/) for more information and examples on the **Port** parameter of Serverless Containers.

## Privacy policy

A container's privacy policy defines whether a container may be invoked anonymously (**public**) or only via an authentication mechanism provided by the [Scaleway API](https://www.scaleway.com/en/developers/api/serverless-containers/#authentication) (**private**).

### IAM authentication

Scaleway IAM provides a modern, secure, and integrated method of authentication for private containers, based on an IAM application bearing an API key, targeted by an IAM policy with the `ContainersPrivateAccess` permission set.

Refer to the [dedicated documentation](/serverless-containers/how-to/create-auth-token-from-console/) for more information on how to set up authentication for your private containers.

### JWT Token (legacy)

JWT (JSON Web Token) is an access token you can create to enable an application to access your `private` container. [Find out how to restrict access to a container](/serverless-containers/how-to/secure-a-container/#restrict-access-to-your-containers).

<Message type="important">
Scaleway Serverless Containers used to rely on JWT authentication tokens to access private resources. This feature is now deprecated, you must therefore use [IAM authentication](#iam-authentication) to access your private containers using an [API key](/iam/how-to/create-api-keys/).
</Message>

## Private Networks

Scaleway Serverless Containers support Private Networks.

Private Networks let you connect Scaleway resources across multiple AZs within the same region. Attached resources can then communicate between themselves in an isolated and secure layer 2 network, away from the public internet.

**D**ynamic **H**ost **C**onfiguration **P**rotocol (DHCP) is built into each Private Network, making it easy to manage the private IP addresses of your resources on the network.

Read our dedicated documentation on [use Private Networks](/serverless-containers/how-to/use-private-networks/).

<Message type="note">
Previously, Private Networks at Scaleway were zoned. Only resources from within one defined AZ could be attached to each network. Now, all Private Networks are regional, and resources from any AZ within that network's region can be attached. "Old" zoned Private Networks have all been automatically migrated to become regional.

While DHCP is built into all new Private Networks, it may not be automatically activated for older Private Networks. Check our [migration](/vpc/reference-content/vpc-migration/) documentation for more information.
</Message>

## Registry endpoint

The registry endpoint parameter is the resource linked to the container image used in your Serverless Container. Endpoints for the [Scaleway Container Registry](/container-registry/) namespaces can be found in the Scaleway Console.

## Request timeout

Request timeout is the maximum amount of time a request to a Serverless Container is allowed to run before the request is terminated. The purpose of this parameter is to ensure long-running requests do not hang indefinitely, which could impact resource usage and scalability.

Use cases:
* **Shorter timeouts:** Ideal for use cases with quick, predictable response times, such as HTTP APIs or real-time applications.
* **Longer timeouts:** Useful for tasks requiring extended processing times, like data processing, report generation, or integration with slower external services.

## Rolling update

When deploying a new version of a Serverless Container, a rolling update is applied by default. The new version of the service is gradually rolled out to your users without downtime, as follows:

* When a new version of your container is deployed, the platform automatically starts routing traffic to it incrementally, while still serving requests from the old version until the new one is fully deployed.
* Once the new version is successfully running, the platform gradually shifts all traffic to it, ensuring zero downtime.
* The old version is decommissioned once the new version is fully serving traffic.

This process ensures a seamless update experience, minimizing user disruption during deployments. If needed, you can also manage traffic splitting between versions during the update process, allowing you to test new versions with a subset of traffic before fully migrating to it.

## Sandbox

A sandbox is an isolation area for your container. Serverless Containers offer two sandboxing environments:
- **v1** - Legacy sandboxing with slower cold starts, but fully supports Linux syscall interface.
- **v2** - Recommended for faster cold starts, but only supports a selection of Linux syscalls.

Refer to the [dedicated documentation](/serverless-containers/reference-content/containers-sandbox/) for more information on sandbox environments.

## Secrets

Secrets are an extra-secure type of environment variable. They are environment variables that are injected into your container and stored securely, but not displayed in the console after initial validation. Secrets defined at the container level override the ones defined at the namespace level if they have the same name.

Secrets on Serverless Containers are not linked with Secret Manager product yet.

## Serverless

Serverless allows you to deploy your Functions (FaaS) and Containerized Applications (CaaS) in a managed infrastructure. Scaleway ensures the deployment, availability, and scalability of all your projects.

For more details about the advantages of using Serverless, [read the Serverless overview page](/serverless-containers/reference-content/serverless-overview/).

## Serverless Framework

Serverless.com (Serverless Framework) is a tool that allows you to deploy serverless applications without having to manage Serverless Container's API call. Write and deploy a YAML configuration file, everything else is handled automatically, even the image building.

<ServerlessConcepts />

## Stateless

Refers to a system or application that does not maintain any persistent state between executions. In a stateless environment, each request or operation is independent, and no information is retained from previous interactions.

This means that each request is treated as a new and isolated event, and there is no need for the system to remember previous states or data once a task is completed. Statelessness is commonly used in serverless architectures where each function execution is independent of others.

To store data you can use [Scaleway Object Storage](/object-storage/), [Scaleway Managed Databases](/managed-databases-for-postgresql-and-mysql/), and [Scaleway Serverless Databases](/serverless-sql-databases/).

## Status

A Serverless Container can have the following statuses:
* **Ready**: your Serverless Container is operational to serve requests.
* **Pending**: your resource is under deployment.
* **Error**: something went wrong during the deployment process. [Check our troubleshooting documentation](/serverless-containers/troubleshooting/cannot-deploy-image) to solve the issue.

## Triggers

For Serverless Containers, a trigger is a setting that can start events that automatically interacts your service.

A trigger could be an incoming scheduled HTTP request or a message being published to a queue. When the event occurs, the trigger invokes your service to run its code.

### CRON trigger

A CRON trigger is a mechanism used to automatically invoke a Serverless Container at a specific time on a recurring schedule.

It works similarly to a traditional Linux [cron job](https://en.wikipedia.org/wiki/Cron), using the `* * * * *` format, and uses the **UTC** time zone. Refer to our [cron schedules reference](/serverless-containers/reference-content/cron-schedules/) for more information.

It allows Serverless Containers to execute scheduled tasks, like managing other resources, generating backups and waking up the Container at specific times.

### Queue trigger

A queue trigger is a mechanism that connects a container to a queue created with [Scaleway Queues](/queues/concepts/#scaleway-queues), and invokes the container automatically whenever a message is added to the queue.

For each message that is sent to a queue, the trigger reads the message and invokes the associated container with the message as the input parameter.
The container can then process the message, and perform any required actions, such as updating a database or sending a notification.

Refer to the [dedicated documentation](/serverless-containers/how-to/add-trigger-to-a-container/) for more information on how to add triggers to a Serverless Container.

### NATS trigger

A NATS trigger is a mechanism that connects a container to a [NATS](/nats/concepts/#nats) subject and invokes the container automatically whenever a message is published to the subject.

For each message that is sent to a NATS subject, the NATS trigger reads the message and invokes the associated container with the message as the input parameter.
The container can then process the message and perform any required actions, such as updating a database or sending a notification.

Refer to the [dedicated documentation](/serverless-containers/how-to/add-trigger-to-a-container/) for more information on how to add triggers to a Serverless Container.

## Terraform/OpenTofu

Terraform/OpenTofu is a tool for managing infrastructure using code. [Read the Terraform/OpenTofu documentation for Serverless Containers](https://registry.terraform.io/providers/scaleway/scaleway/latest/docs/resources/container).

## Protocol

Serverless Containers supports **http1** (default) and **http2** (`h2c`). Use HTTP/2 if your container application is configured to listen for HTTP/2 requests, such as a **gRPC** service or a web server that uses HTTP/2 features like multiplexing, otherwise, HTTP/1 is recommended.

<Message type="note">
HTTP/1.0 is not supported. Refer to the [dedicated troubleshooting page](/serverless-containers/troubleshooting/http1-errors/) for more information.
</Message>

### gRPC

gRPC is supported on Serverless Containers, as long as you have enabled http2 (`h2c`) protocol.

## Units

Units are standardized measures of the computational resources, such as processing power and memory, allocated to run your service. The quantity of units you assign determines your application's performance capacity and directly influences its cost.

### vCPU

vCPU is the abbreviation for **v**irtual **C**entralized **P**rocessing **U**nit. A vCPU represents a portion or share of the underlying physical CPU assigned to a particular container.
The performance of a vCPU is determined by the percentage of time spent on the physical processor's core. It is possible to allocate different resource allowances on specific vCPUs for specific containers or virtual machines.

### mvCPU

A [vCPU](#vcpu) (Virtual Central Processing Unit) is equivalent to 1000 mvCPU.

### vCPU-s

Unit used to measure the resource consumption of a container. It reflects the amount of vCPU used over time in seconds.

### GB-s

Unit used to measure the RAM consumption of a container. It reflects the amount of memory consumed over time in seconds.
